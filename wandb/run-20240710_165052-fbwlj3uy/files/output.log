I0710 16:51:00.115324 139160126928704 02_finetune_new_observation_action.py:59] Loading pre-trained model...
Fetching 8 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 27346.73it/s]
/home/yunqiliu/anaconda3/envs/torch/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
W0710 16:51:04.494328 139160126928704 block_transformer.py:295] Using old attention computation from released December models.
I0710 16:51:12.471403 139160126928704 checkpointer.py:164] Restoring item from /home/yunqiliu/.cache/huggingface/hub/models--rail-berkeley--octo-small/snapshots/03d88976c54a58e10480d2043a8c762b35bc2611/270000/default.
I0710 16:51:13.118540 139160126928704 checkpointer.py:166] Finished restoring checkpoint from /home/yunqiliu/.cache/huggingface/hub/models--rail-berkeley--octo-small/snapshots/03d88976c54a58e10480d2043a8c762b35bc2611/270000/default.
/home/yunqiliu/anaconda3/envs/torch/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
I0710 16:51:14.738392 139160126928704 02_finetune_new_observation_action.py:68] Loading finetuning dataset...
I0710 16:51:14.744272 139160126928704 dataset_info.py:578] Load dataset info from /home/yunqiliu/tensorflow_datasets/aloha_sim_cube_scripted_dataset/1.0.0
I0710 16:51:15.006677 139160126928704 logging_logger.py:49] Constructing tf.data.Dataset aloha_sim_cube_scripted_dataset for split all, from /home/yunqiliu/tensorflow_datasets/aloha_sim_cube_scripted_dataset/1.0.0
I0710 16:51:15.733802 139160126928704 function_wrappers.py:112] Sampling uniformly across keys: ['language_instruction']
I0710 16:51:15.953588 139160126928704 data_utils.py:113] Loading existing dataset statistics from /home/yunqiliu/tensorflow_datasets/aloha_sim_cube_scripted_dataset/1.0.0/dataset_statistics_6e9a30171a12844cc8c8c309ca19f52e9b09ba3dce8b5c743bb122a40baba07c.json.
I0710 16:51:15.993795 139160126928704 logging_logger.py:49] Constructing tf.data.Dataset aloha_sim_cube_scripted_dataset for split train[:95%], from /home/yunqiliu/tensorflow_datasets/aloha_sim_cube_scripted_dataset/1.0.0
I0710 16:51:16.051795 139160126928704 function_wrappers.py:112] Sampling uniformly across keys: ['language_instruction']
This model is trained with a window size of 2, predicting 7 dimensional actions 4 steps into the future.
Observations and tasks conform to the following spec:
Observations: {
    image_primary: ('batch', 'history_window', 256, 256, 3),
    image_wrist: ('batch', 'history_window', 128, 128, 3),
}
Tasks: {
    image_primary: ('batch', 256, 256, 3),
    image_wrist: ('batch', 128, 128, 3),
    language_instruction: {
        attention_mask: ('batch', 16),
        input_ids: ('batch', 16),
    },
}
At inference, you may pass in any subset of these observation and task keys, with a history window up to 2 timesteps.
I0710 16:51:24.778524 139160126928704 02_finetune_new_observation_action.py:128] Updating model for new observation & action space...
I0710 16:51:26.030846 139160126928704 tokenizers.py:124] No task inputs matching image_primary were found. Replacing with zero padding.
[3m                                                        Attention Mask                                                         
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ[1m                                [22mâ”ƒ[1m task_language (16    [22mâ”ƒ[1m t=0 obs_primary (256 [22mâ”ƒ[1m t=0 obs_proprio (14   [22mâ”ƒ[1m t=0 readout_action   [22mâ”ƒ
â”ƒ[1m                                [22mâ”ƒ[1m tokens)              [22mâ”ƒ[1m tokens)              [22mâ”ƒ[1m tokens)               [22mâ”ƒ[1m (1 tokens)           [22mâ”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ task_language (16 tokens)      â”‚ x                    â”‚ x                    â”‚ x                     â”‚ x                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ t=0 obs_primary (256 tokens)   â”‚                      â”‚ x                    â”‚ x                     â”‚ x                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ t=0 obs_proprio (14 tokens)    â”‚                      â”‚ x                    â”‚ x                     â”‚ x                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ t=0 readout_action (1 tokens)  â”‚                      â”‚                      â”‚                       â”‚ x                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
W0710 16:51:26.232446 139160126928704 block_transformer.py:410] Prefix groups:
W0710 16:51:26.232908 139160126928704 block_transformer.py:412] PrefixGroup(name=task_language, shape=(1, 16, 384), attends_to={
    task_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
})
W0710 16:51:26.233042 139160126928704 block_transformer.py:418] Timestep groups:
W0710 16:51:26.233170 139160126928704 block_transformer.py:420] TimestepGroup(name=obs_primary, shape=(1, 1, 256, 384), attends_to={
    task_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
    obs_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
})
W0710 16:51:26.233270 139160126928704 block_transformer.py:420] TimestepGroup(name=obs_proprio, shape=(1, 1, 14, 384), attends_to={
    task_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
    obs_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
})
W0710 16:51:26.233417 139160126928704 block_transformer.py:420] TimestepGroup(name=readout_action, shape=(1, 1, 1, 384), attends_to={
    task_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
    obs_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
    readout_action: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
})
W0710 16:51:26.240814 139160126928704 block_transformer.py:295] Using old attention computation from released December models.
/home/yunqiliu/anaconda3/envs/torch/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
I0710 16:51:29.923958 139160126928704 tokenizers.py:124] No task inputs matching image_primary were found. Replacing with zero padding.
W0710 16:51:30.011518 139160126928704 block_transformer.py:295] Using old attention computation from released December models.
[3m                                                      OctoModule Summary                                                       
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ[1m path                    [22mâ”ƒ[1m module                [22mâ”ƒ[1m inputs                 [22mâ”ƒ[1m outputs                 [22mâ”ƒ[1m params                 [22mâ”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚                         â”‚ OctoModule            â”‚ - image_primary:       â”‚ - obs:                  â”‚                        â”‚
â”‚                         â”‚                       â”‚ uint8[1,1,256,256,3]   â”‚     mask: bool[1,1,270] â”‚                        â”‚
â”‚                         â”‚                       â”‚   pad_mask_dict:       â”‚     tokens:             â”‚                        â”‚
â”‚                         â”‚                       â”‚     image_primary:     â”‚ float32[1,1,270,384]    â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1,1]              â”‚   obs_primary:          â”‚                        â”‚
â”‚                         â”‚                       â”‚     proprio: bool[1,1] â”‚     mask: bool[1,1,256] â”‚                        â”‚
â”‚                         â”‚                       â”‚     timestep:          â”‚     tokens:             â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1,1]              â”‚ float32[1,1,256,384]    â”‚                        â”‚
â”‚                         â”‚                       â”‚   proprio:             â”‚   obs_proprio:          â”‚                        â”‚
â”‚                         â”‚                       â”‚ float32[1,1,14]        â”‚     mask: bool[1,1,14]  â”‚                        â”‚
â”‚                         â”‚                       â”‚   task_completed:      â”‚     tokens:             â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1,1,50]           â”‚ float32[1,1,14,384]     â”‚                        â”‚
â”‚                         â”‚                       â”‚   timestep: int32[1,1] â”‚   readout_action:       â”‚                        â”‚
â”‚                         â”‚                       â”‚   timestep_pad_mask:   â”‚     mask:               â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1,1]              â”‚ float32[1,1,1]          â”‚                        â”‚
â”‚                         â”‚                       â”‚ -                      â”‚     tokens:             â”‚                        â”‚
â”‚                         â”‚                       â”‚ language_instruction:  â”‚ float32[1,1,1,384]      â”‚                        â”‚
â”‚                         â”‚                       â”‚     attention_mask:    â”‚   task:                 â”‚                        â”‚
â”‚                         â”‚                       â”‚ int32[1,16]            â”‚     mask: bool[1,16]    â”‚                        â”‚
â”‚                         â”‚                       â”‚     input_ids:         â”‚     tokens:             â”‚                        â”‚
â”‚                         â”‚                       â”‚ int32[1,16]            â”‚ float32[1,16,384]       â”‚                        â”‚
â”‚                         â”‚                       â”‚   pad_mask_dict:       â”‚   task_language:        â”‚                        â”‚
â”‚                         â”‚                       â”‚     language_instructâ€¦ â”‚     mask: bool[1,16]    â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1]                â”‚     tokens:             â”‚                        â”‚
â”‚                         â”‚                       â”‚ - bool[1,1]            â”‚ float32[1,16,384]       â”‚                        â”‚
â”‚                         â”‚                       â”‚ - train: False         â”‚ - action:               â”‚                        â”‚
â”‚                         â”‚                       â”‚   verbose: True        â”‚ float32[1,1,50,14]      â”‚                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transformer        â”‚ OctoTransformer       â”‚ - image_primary:       â”‚ obs:                    â”‚ obs_primary_pos_embedâ€¦ â”‚
â”‚                         â”‚                       â”‚ uint8[1,1,256,256,3]   â”‚   mask: bool[1,1,270]   â”‚ float32[1,10,256,384]  â”‚
â”‚                         â”‚                       â”‚   pad_mask_dict:       â”‚   tokens:               â”‚ obs_proprio_pos_embedâ€¦ â”‚
â”‚                         â”‚                       â”‚     image_primary:     â”‚ float32[1,1,270,384]    â”‚ float32[1,10,14,384]   â”‚
â”‚                         â”‚                       â”‚ bool[1,1]              â”‚ obs_primary:            â”‚ readout_action_pos_emâ€¦ â”‚
â”‚                         â”‚                       â”‚     proprio: bool[1,1] â”‚   mask: bool[1,1,256]   â”‚ float32[1,10,1,384]    â”‚
â”‚                         â”‚                       â”‚     timestep:          â”‚   tokens:               â”‚ task_language_pos_embâ€¦ â”‚
â”‚                         â”‚                       â”‚ bool[1,1]              â”‚ float32[1,1,256,384]    â”‚ float32[1,16,384]      â”‚
â”‚                         â”‚                       â”‚   proprio:             â”‚ obs_proprio:            â”‚                        â”‚
â”‚                         â”‚                       â”‚ float32[1,1,14]        â”‚   mask: bool[1,1,14]    â”‚ [1m1,046,784 (4.2 MB)[22m     â”‚
â”‚                         â”‚                       â”‚   task_completed:      â”‚   tokens:               â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1,1,50]           â”‚ float32[1,1,14,384]     â”‚                        â”‚
â”‚                         â”‚                       â”‚   timestep: int32[1,1] â”‚ readout_action:         â”‚                        â”‚
â”‚                         â”‚                       â”‚   timestep_pad_mask:   â”‚   mask: float32[1,1,1]  â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1,1]              â”‚   tokens:               â”‚                        â”‚
â”‚                         â”‚                       â”‚ -                      â”‚ float32[1,1,1,384]      â”‚                        â”‚
â”‚                         â”‚                       â”‚ language_instruction:  â”‚ task:                   â”‚                        â”‚
â”‚                         â”‚                       â”‚     attention_mask:    â”‚   mask: bool[1,16]      â”‚                        â”‚
â”‚                         â”‚                       â”‚ int32[1,16]            â”‚   tokens:               â”‚                        â”‚
â”‚                         â”‚                       â”‚     input_ids:         â”‚ float32[1,16,384]       â”‚                        â”‚
â”‚                         â”‚                       â”‚ int32[1,16]            â”‚ task_language:          â”‚                        â”‚
â”‚                         â”‚                       â”‚   pad_mask_dict:       â”‚   mask: bool[1,16]      â”‚                        â”‚
â”‚                         â”‚                       â”‚     language_instructâ€¦ â”‚   tokens:               â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1]                â”‚ float32[1,16,384]       â”‚                        â”‚
â”‚                         â”‚                       â”‚ - bool[1,1]            â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ - train: False         â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   verbose: True        â”‚                         â”‚                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ encoder                 â”‚ FlaxT5Stack           â”‚ attention_mask:        â”‚ attentions: None        â”‚                        â”‚
â”‚                         â”‚                       â”‚ int32[1,1]             â”‚ cross_attentions: None  â”‚                        â”‚
â”‚                         â”‚                       â”‚ deterministic: True    â”‚ hidden_states: None     â”‚                        â”‚
â”‚                         â”‚                       â”‚ input_ids: int32[1,1]  â”‚ last_hidden_state:      â”‚                        â”‚
â”‚                         â”‚                       â”‚ output_attentions:     â”‚ float32[1,1,768]        â”‚                        â”‚
â”‚                         â”‚                       â”‚ False                  â”‚ past_key_values: None   â”‚                        â”‚
â”‚                         â”‚                       â”‚ output_hidden_states:  â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ False                  â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ return_dict: True      â”‚                         â”‚                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ shared                  â”‚ Embed                 â”‚ int32[1,1]             â”‚ float32[1,1,768]        â”‚                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ encoder/dropout         â”‚ Dropout               â”‚ - float32[1,1,768]     â”‚ float32[1,1,768]        â”‚                        â”‚
â”‚                         â”‚                       â”‚ - deterministic: True  â”‚                         â”‚                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ encoder/block           â”‚ FlaxT5BlockCollection â”‚ - float32[1,1,768]     â”‚ attentions: None        â”‚                        â”‚
â”‚                         â”‚                       â”‚ - attention_mask:      â”‚ cross_attentions: None  â”‚                        â”‚
â”‚                         â”‚                       â”‚ int32[1,1]             â”‚ hidden_states: None     â”‚                        â”‚
â”‚                         â”‚                       â”‚   deterministic: True  â”‚ last_hidden_state:      â”‚                        â”‚
â”‚                         â”‚                       â”‚   encoder_attention_mâ€¦ â”‚ float32[1,1,768]        â”‚                        â”‚
â”‚                         â”‚                       â”‚ None                   â”‚ past_key_values: None   â”‚                        â”‚
â”‚                         â”‚                       â”‚   encoder_hidden_statâ€¦ â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ None                   â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   init_cache: False    â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   output_attentions:   â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ False                  â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   output_hidden_stateâ€¦ â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ False                  â”‚                         â”‚                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ encoder/final_layer_noâ€¦ â”‚ FlaxT5LayerNorm       â”‚ float32[1,1,768]       â”‚ float32[1,1,768]        â”‚                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transformer/task_â€¦ â”‚ LanguageTokenizer     â”‚ - image_primary:       â”‚ mask: bool[1,16]        â”‚ [1m109,628,544 (438.5 MB)[22m â”‚
â”‚                         â”‚                       â”‚ uint8[1,1,256,256,3]   â”‚ tokens:                 â”‚                        â”‚
â”‚                         â”‚                       â”‚   pad_mask_dict:       â”‚ float32[1,16,768]       â”‚                        â”‚
â”‚                         â”‚                       â”‚     image_primary:     â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1,1]              â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     proprio: bool[1,1] â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     timestep:          â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1,1]              â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   proprio:             â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ float32[1,1,14]        â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   task_completed:      â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1,1,50]           â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   timestep: int32[1,1] â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   timestep_pad_mask:   â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1,1]              â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ -                      â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ language_instruction:  â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     attention_mask:    â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ int32[1,16]            â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     input_ids:         â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ int32[1,16]            â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   pad_mask_dict:       â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     language_instructâ€¦ â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1]                â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ - train: False         â”‚                         â”‚                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transformer/task_â€¦ â”‚ Dense                 â”‚ float32[1,16,768]      â”‚ float32[1,16,384]       â”‚ bias: float32[384]     â”‚
â”‚                         â”‚                       â”‚                        â”‚                         â”‚ kernel:                â”‚
â”‚                         â”‚                       â”‚                        â”‚                         â”‚ float32[768,384]       â”‚
â”‚                         â”‚                       â”‚                        â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚                        â”‚                         â”‚ [1m295,296 (1.2 MB)[22m       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transformer/obserâ€¦ â”‚ ImageTokenizer        â”‚ - image_primary:       â”‚ mask: bool[1,1,256]     â”‚ [1m1,058,048 (4.2 MB)[22m     â”‚
â”‚                         â”‚                       â”‚ uint8[1,1,256,256,3]   â”‚ tokens:                 â”‚                        â”‚
â”‚                         â”‚                       â”‚   pad_mask_dict:       â”‚ float32[1,1,256,512]    â”‚                        â”‚
â”‚                         â”‚                       â”‚     image_primary:     â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1,1]              â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     proprio: bool[1,1] â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     timestep:          â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1,1]              â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   proprio:             â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ float32[1,1,14]        â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   task_completed:      â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1,1,50]           â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   timestep: int32[1,1] â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   timestep_pad_mask:   â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1,1]              â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ -                      â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ language_instruction:  â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     attention_mask:    â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ int32[1,16]            â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     input_ids:         â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ int32[1,16]            â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   pad_mask_dict:       â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     language_instructâ€¦ â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1]                â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ - train: False         â”‚                         â”‚                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transformer/obs_pâ€¦ â”‚ Dense                 â”‚ float32[1,1,256,512]   â”‚ float32[1,1,256,384]    â”‚ bias: float32[384]     â”‚
â”‚                         â”‚                       â”‚                        â”‚                         â”‚ kernel:                â”‚
â”‚                         â”‚                       â”‚                        â”‚                         â”‚ float32[512,384]       â”‚
â”‚                         â”‚                       â”‚                        â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚                        â”‚                         â”‚ [1m196,992 (788.0 KB)[22m     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transformer/obserâ€¦ â”‚ LowdimObsTokenizer    â”‚ - image_primary:       â”‚ mask: float32[1,1,14]   â”‚                        â”‚
â”‚                         â”‚                       â”‚ uint8[1,1,256,256,3]   â”‚ tokens:                 â”‚                        â”‚
â”‚                         â”‚                       â”‚   pad_mask_dict:       â”‚ float32[1,1,14,1]       â”‚                        â”‚
â”‚                         â”‚                       â”‚     image_primary:     â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1,1]              â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     proprio: bool[1,1] â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     timestep:          â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1,1]              â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   proprio:             â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ float32[1,1,14]        â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   task_completed:      â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1,1,50]           â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   timestep: int32[1,1] â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   timestep_pad_mask:   â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1,1]              â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ -                      â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ language_instruction:  â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     attention_mask:    â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ int32[1,16]            â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     input_ids:         â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ int32[1,16]            â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   pad_mask_dict:       â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     language_instructâ€¦ â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1]                â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ - train: False         â”‚                         â”‚                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transformer/obs_pâ€¦ â”‚ Dense                 â”‚ float32[1,1,14,1]      â”‚ float32[1,1,14,384]     â”‚ bias: float32[384]     â”‚
â”‚                         â”‚                       â”‚                        â”‚                         â”‚ kernel: float32[1,384] â”‚
â”‚                         â”‚                       â”‚                        â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚                        â”‚                         â”‚ [1m768 (3.1 KB)[22m           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transformer/Blockâ€¦ â”‚ BlockTransformer      â”‚ - - attention_rules:   â”‚ - - attention_rules:    â”‚ [1m21,294,336 (85.2 MB)[22m   â”‚
â”‚                         â”‚                       â”‚       task_*:          â”‚       task_*:           â”‚                        â”‚
â”‚                         â”‚                       â”‚ <AttentionRule.CAUSAL: â”‚ <AttentionRule.CAUSAL:  â”‚                        â”‚
â”‚                         â”‚                       â”‚ other.timestep <=      â”‚ other.timestep <=       â”‚                        â”‚
â”‚                         â”‚                       â”‚ self.timestep>         â”‚ self.timestep>          â”‚                        â”‚
â”‚                         â”‚                       â”‚     mask: bool[1,16]   â”‚     mask: bool[1,16]    â”‚                        â”‚
â”‚                         â”‚                       â”‚     name:              â”‚     name: task_language â”‚                        â”‚
â”‚                         â”‚                       â”‚ task_language          â”‚     tokens:             â”‚                        â”‚
â”‚                         â”‚                       â”‚     tokens:            â”‚ float32[1,16,384]       â”‚                        â”‚
â”‚                         â”‚                       â”‚ float32[1,16,384]      â”‚ - - attention_rules:    â”‚                        â”‚
â”‚                         â”‚                       â”‚ - - attention_rules:   â”‚       obs_*:            â”‚                        â”‚
â”‚                         â”‚                       â”‚       obs_*:           â”‚ <AttentionRule.CAUSAL:  â”‚                        â”‚
â”‚                         â”‚                       â”‚ <AttentionRule.CAUSAL: â”‚ other.timestep <=       â”‚                        â”‚
â”‚                         â”‚                       â”‚ other.timestep <=      â”‚ self.timestep>          â”‚                        â”‚
â”‚                         â”‚                       â”‚ self.timestep>         â”‚       task_*:           â”‚                        â”‚
â”‚                         â”‚                       â”‚       task_*:          â”‚ <AttentionRule.CAUSAL:  â”‚                        â”‚
â”‚                         â”‚                       â”‚ <AttentionRule.CAUSAL: â”‚ other.timestep <=       â”‚                        â”‚
â”‚                         â”‚                       â”‚ other.timestep <=      â”‚ self.timestep>          â”‚                        â”‚
â”‚                         â”‚                       â”‚ self.timestep>         â”‚     mask: bool[1,1,256] â”‚                        â”‚
â”‚                         â”‚                       â”‚     mask:              â”‚     name: obs_primary   â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1,1,256]          â”‚     tokens:             â”‚                        â”‚
â”‚                         â”‚                       â”‚     name: obs_primary  â”‚ float32[1,1,256,384]    â”‚                        â”‚
â”‚                         â”‚                       â”‚     tokens:            â”‚   - attention_rules:    â”‚                        â”‚
â”‚                         â”‚                       â”‚ float32[1,1,256,384]   â”‚       obs_*:            â”‚                        â”‚
â”‚                         â”‚                       â”‚   - attention_rules:   â”‚ <AttentionRule.CAUSAL:  â”‚                        â”‚
â”‚                         â”‚                       â”‚       obs_*:           â”‚ other.timestep <=       â”‚                        â”‚
â”‚                         â”‚                       â”‚ <AttentionRule.CAUSAL: â”‚ self.timestep>          â”‚                        â”‚
â”‚                         â”‚                       â”‚ other.timestep <=      â”‚       task_*:           â”‚                        â”‚
â”‚                         â”‚                       â”‚ self.timestep>         â”‚ <AttentionRule.CAUSAL:  â”‚                        â”‚
â”‚                         â”‚                       â”‚       task_*:          â”‚ other.timestep <=       â”‚                        â”‚
â”‚                         â”‚                       â”‚ <AttentionRule.CAUSAL: â”‚ self.timestep>          â”‚                        â”‚
â”‚                         â”‚                       â”‚ other.timestep <=      â”‚     mask: bool[1,1,14]  â”‚                        â”‚
â”‚                         â”‚                       â”‚ self.timestep>         â”‚     name: obs_proprio   â”‚                        â”‚
â”‚                         â”‚                       â”‚     mask: bool[1,1,14] â”‚     tokens:             â”‚                        â”‚
â”‚                         â”‚                       â”‚     name: obs_proprio  â”‚ float32[1,1,14,384]     â”‚                        â”‚
â”‚                         â”‚                       â”‚     tokens:            â”‚   - attention_rules:    â”‚                        â”‚
â”‚                         â”‚                       â”‚ float32[1,1,14,384]    â”‚       obs_*:            â”‚                        â”‚
â”‚                         â”‚                       â”‚   - attention_rules:   â”‚ <AttentionRule.CAUSAL:  â”‚                        â”‚
â”‚                         â”‚                       â”‚       obs_*:           â”‚ other.timestep <=       â”‚                        â”‚
â”‚                         â”‚                       â”‚ <AttentionRule.CAUSAL: â”‚ self.timestep>          â”‚                        â”‚
â”‚                         â”‚                       â”‚ other.timestep <=      â”‚       readout_action:   â”‚                        â”‚
â”‚                         â”‚                       â”‚ self.timestep>         â”‚ <AttentionRule.CAUSAL:  â”‚                        â”‚
â”‚                         â”‚                       â”‚       readout_action:  â”‚ other.timestep <=       â”‚                        â”‚
â”‚                         â”‚                       â”‚ <AttentionRule.CAUSAL: â”‚ self.timestep>          â”‚                        â”‚
â”‚                         â”‚                       â”‚ other.timestep <=      â”‚       task_*:           â”‚                        â”‚
â”‚                         â”‚                       â”‚ self.timestep>         â”‚ <AttentionRule.CAUSAL:  â”‚                        â”‚
â”‚                         â”‚                       â”‚       task_*:          â”‚ other.timestep <=       â”‚                        â”‚
â”‚                         â”‚                       â”‚ <AttentionRule.CAUSAL: â”‚ self.timestep>          â”‚                        â”‚
â”‚                         â”‚                       â”‚ other.timestep <=      â”‚     mask:               â”‚                        â”‚
â”‚                         â”‚                       â”‚ self.timestep>         â”‚ float32[1,1,1]          â”‚                        â”‚
â”‚                         â”‚                       â”‚     mask:              â”‚     name:               â”‚                        â”‚
â”‚                         â”‚                       â”‚ float32[1,1,1]         â”‚ readout_action          â”‚                        â”‚
â”‚                         â”‚                       â”‚     name:              â”‚     tokens:             â”‚                        â”‚
â”‚                         â”‚                       â”‚ readout_action         â”‚ float32[1,1,1,384]      â”‚                        â”‚
â”‚                         â”‚                       â”‚     tokens:            â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ float32[1,1,1,384]     â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ - train: False         â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   verbose: True        â”‚                         â”‚                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ heads_action            â”‚ L1ActionHead          â”‚ - obs:                 â”‚ float32[1,1,50,14]      â”‚                        â”‚
â”‚                         â”‚                       â”‚     mask:              â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1,1,270]          â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     tokens:            â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ float32[1,1,270,384]   â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   obs_primary:         â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     mask:              â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1,1,256]          â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     tokens:            â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ float32[1,1,256,384]   â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   obs_proprio:         â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     mask: bool[1,1,14] â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     tokens:            â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ float32[1,1,14,384]    â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   readout_action:      â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     mask:              â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ float32[1,1,1]         â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     tokens:            â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ float32[1,1,1,384]     â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   task:                â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     mask: bool[1,16]   â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     tokens:            â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ float32[1,16,384]      â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   task_language:       â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     mask: bool[1,16]   â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     tokens:            â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ float32[1,16,384]      â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ - train: False         â”‚                         â”‚                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ heads_action/map_head   â”‚ MAPHead               â”‚ - mask: float32[1,1,1] â”‚ float32[1,1,1,384]      â”‚ probe:                 â”‚
â”‚                         â”‚                       â”‚   tokens:              â”‚                         â”‚ float32[1,1,384]       â”‚
â”‚                         â”‚                       â”‚ float32[1,1,1,384]     â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ - train: False         â”‚                         â”‚ [1m1,774,080 (7.1 MB)[22m     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ heads_action/mean_proj  â”‚ Dense                 â”‚ float32[1,1,384]       â”‚ float32[1,1,700]        â”‚ bias: float32[700]     â”‚
â”‚                         â”‚                       â”‚                        â”‚                         â”‚ kernel:                â”‚
â”‚                         â”‚                       â”‚                        â”‚                         â”‚ float32[384,700]       â”‚
â”‚                         â”‚                       â”‚                        â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚                        â”‚                         â”‚ [1m269,500 (1.1 MB)[22m       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚[1m                         [22mâ”‚[1m                       [22mâ”‚[1m                        [22mâ”‚[1m                   Total [22mâ”‚[1m 135,564,348 (542.3 MB) [22mâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
[1m                                                                                                                               
[1m                                           Total Parameters: 135,564,348 (542.3 MB)                                            
I0710 16:51:37.306917 139160126928704 compilation_cache.py:101] Writing jit__init to persistent compilation cache with key jit__init-5bbbe64742b65329948afec0a07670028676039bfdb44d132a0815f489175644.
I0710 16:51:37.600662 139160126928704 train_utils.py:405] ########## Parameters skipped during model loading: ##########
I0710 16:51:37.600907 139160126928704 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.LayerNorm_0.bias
I0710 16:51:37.600986 139160126928704 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.LayerNorm_0.scale
I0710 16:51:37.601034 139160126928704 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MlpBlock_0.Dense_0.bias
I0710 16:51:37.601079 139160126928704 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MlpBlock_0.Dense_0.kernel
I0710 16:51:37.601122 139160126928704 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MlpBlock_0.Dense_1.bias
I0710 16:51:37.601162 139160126928704 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MlpBlock_0.Dense_1.kernel
I0710 16:51:37.601205 139160126928704 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MultiHeadDotProductAttention_0.key.bias
I0710 16:51:37.601249 139160126928704 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MultiHeadDotProductAttention_0.key.kernel
I0710 16:51:37.601293 139160126928704 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MultiHeadDotProductAttention_0.out.bias
I0710 16:51:37.601334 139160126928704 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MultiHeadDotProductAttention_0.out.kernel
I0710 16:51:37.601375 139160126928704 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MultiHeadDotProductAttention_0.query.bias
I0710 16:51:37.601416 139160126928704 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MultiHeadDotProductAttention_0.query.kernel
I0710 16:51:37.601460 139160126928704 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MultiHeadDotProductAttention_0.value.bias
I0710 16:51:37.601504 139160126928704 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MultiHeadDotProductAttention_0.value.kernel
I0710 16:51:37.601550 139160126928704 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.probe
I0710 16:51:37.601593 139160126928704 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.mean_proj.bias
I0710 16:51:37.601634 139160126928704 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.mean_proj.kernel
I0710 16:51:37.601675 139160126928704 train_utils.py:407] Param missing in pre-trained model, skipping: octo_transformer.obs_proprio_pos_embedding
I0710 16:51:37.601716 139160126928704 train_utils.py:407] Param missing in pre-trained model, skipping: octo_transformer.obs_proprio_projection.bias
I0710 16:51:37.601758 139160126928704 train_utils.py:407] Param missing in pre-trained model, skipping: octo_transformer.obs_proprio_projection.kernel
I0710 16:51:37.603751 139160126928704 train_utils.py:250] Freezing parameters that include the following keys: ['*hf_model*'].
I0710 16:51:37.607103 139160126928704 train_utils.py:286] Num trainable params: 25,935,804.
I0710 16:51:37.607213 139160126928704 train_utils.py:287] Num frozen params: 109,628,544.
I0710 16:51:37.607275 139160126928704 train_utils.py:288] To see a detailed list of frozen params, set logging level to DEBUG.
I0710 16:51:39.419423 139160126928704 02_finetune_new_observation_action.py:186] Starting finetuning...
  0%|                                                                                                 | 0/5000 [00:00<?, ?it/s]I0710 16:51:41.095074 139160126928704 tokenizers.py:124] No task inputs matching image_primary were found. Replacing with zero padding.
W0710 16:51:41.312589 139160126928704 block_transformer.py:295] Using old attention computation from released December models.
I0710 16:52:14.564007 139160126928704 compilation_cache.py:101] Writing jit_train_step to persistent compilation cache with key jit_train_step-d4d8d27d125d76c65ff820b7fe6f476b9b297134b0355df68a4b6c06e4f6a93f.


























































































































































































































 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                        | 999/5000 [07:51<29:16,  2.28it/s]I0710 16:59:33.466491 139160126928704 checkpointer.py:134] Saving item to /home/yunqiliu/octo/finetuned_checkpoint/999.orbax-checkpoint-tmp-1720601973367797/default.
I0710 16:59:37.476903 139160126928704 utils.py:529] Renaming /home/yunqiliu/octo/finetuned_checkpoint/999.orbax-checkpoint-tmp-1720601973367797/default.orbax-checkpoint-tmp-1720601973467111 to /home/yunqiliu/octo/finetuned_checkpoint/999.orbax-checkpoint-tmp-1720601973367797/default
I0710 16:59:37.477494 139160126928704 utils.py:573] Finished saving checkpoint to `/home/yunqiliu/octo/finetuned_checkpoint/999.orbax-checkpoint-tmp-1720601973367797/default`.
I0710 16:59:37.482582 139160126928704 utils.py:529] Renaming /home/yunqiliu/octo/finetuned_checkpoint/999.orbax-checkpoint-tmp-1720601973367797 to /home/yunqiliu/octo/finetuned_checkpoint/999

























































































































































































































 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                          | 1999/5000 [15:13<21:51,  2.29it/s]I0710 17:06:55.486686 139160126928704 checkpointer.py:134] Saving item to /home/yunqiliu/octo/finetuned_checkpoint/1999.orbax-checkpoint-tmp-1720602415475780/default.
I0710 17:06:59.221967 139160126928704 utils.py:529] Renaming /home/yunqiliu/octo/finetuned_checkpoint/1999.orbax-checkpoint-tmp-1720602415475780/default.orbax-checkpoint-tmp-1720602415488078 to /home/yunqiliu/octo/finetuned_checkpoint/1999.orbax-checkpoint-tmp-1720602415475780/default
I0710 17:06:59.222471 139160126928704 utils.py:573] Finished saving checkpoint to `/home/yunqiliu/octo/finetuned_checkpoint/1999.orbax-checkpoint-tmp-1720602415475780/default`.
I0710 17:06:59.227075 139160126928704 utils.py:529] Renaming /home/yunqiliu/octo/finetuned_checkpoint/1999.orbax-checkpoint-tmp-1720602415475780 to /home/yunqiliu/octo/finetuned_checkpoint/1999


























































































































































































































 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                            | 2999/5000 [22:35<14:35,  2.29it/s]I0710 17:14:17.594097 139160126928704 checkpointer.py:134] Saving item to /home/yunqiliu/octo/finetuned_checkpoint/2999.orbax-checkpoint-tmp-1720602857587274/default.
I0710 17:14:21.558775 139160126928704 utils.py:529] Renaming /home/yunqiliu/octo/finetuned_checkpoint/2999.orbax-checkpoint-tmp-1720602857587274/default.orbax-checkpoint-tmp-1720602857594655 to /home/yunqiliu/octo/finetuned_checkpoint/2999.orbax-checkpoint-tmp-1720602857587274/default
I0710 17:14:21.559374 139160126928704 utils.py:573] Finished saving checkpoint to `/home/yunqiliu/octo/finetuned_checkpoint/2999.orbax-checkpoint-tmp-1720602857587274/default`.
I0710 17:14:21.563586 139160126928704 utils.py:529] Renaming /home/yunqiliu/octo/finetuned_checkpoint/2999.orbax-checkpoint-tmp-1720602857587274 to /home/yunqiliu/octo/finetuned_checkpoint/2999



























































































































































































































 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰              | 3999/5000 [29:57<07:18,  2.28it/s]I0710 17:21:39.464037 139160126928704 checkpointer.py:134] Saving item to /home/yunqiliu/octo/finetuned_checkpoint/3999.orbax-checkpoint-tmp-1720603299456905/default.
I0710 17:21:43.525782 139160126928704 utils.py:529] Renaming /home/yunqiliu/octo/finetuned_checkpoint/3999.orbax-checkpoint-tmp-1720603299456905/default.orbax-checkpoint-tmp-1720603299464478 to /home/yunqiliu/octo/finetuned_checkpoint/3999.orbax-checkpoint-tmp-1720603299456905/default
I0710 17:21:43.526736 139160126928704 utils.py:573] Finished saving checkpoint to `/home/yunqiliu/octo/finetuned_checkpoint/3999.orbax-checkpoint-tmp-1720603299456905/default`.
I0710 17:21:43.531674 139160126928704 utils.py:529] Renaming /home/yunqiliu/octo/finetuned_checkpoint/3999.orbax-checkpoint-tmp-1720603299456905 to /home/yunqiliu/octo/finetuned_checkpoint/3999


























































































































































































































100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4999/5000 [37:19<00:00,  2.29it/s]I0710 17:29:01.461036 139160126928704 checkpointer.py:134] Saving item to /home/yunqiliu/octo/finetuned_checkpoint/4999.orbax-checkpoint-tmp-1720603741454428/default.
I0710 17:29:04.331645 139160126928704 utils.py:529] Renaming /home/yunqiliu/octo/finetuned_checkpoint/4999.orbax-checkpoint-tmp-1720603741454428/default.orbax-checkpoint-tmp-1720603741461685 to /home/yunqiliu/octo/finetuned_checkpoint/4999.orbax-checkpoint-tmp-1720603741454428/default
I0710 17:29:04.332021 139160126928704 utils.py:573] Finished saving checkpoint to `/home/yunqiliu/octo/finetuned_checkpoint/4999.orbax-checkpoint-tmp-1720603741454428/default`.
I0710 17:29:04.334900 139160126928704 utils.py:529] Renaming /home/yunqiliu/octo/finetuned_checkpoint/4999.orbax-checkpoint-tmp-1720603741454428 to /home/yunqiliu/octo/finetuned_checkpoint/4999
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [37:24<00:00,  2.23it/s]