I0710 15:02:15.191736 125989617137472 02_finetune_new_observation_action.py:60] Loading pre-trained model...
Fetching 8 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 10037.22it/s]
/home/yunqiliu/anaconda3/envs/torch/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
W0710 15:02:19.616104 125989617137472 block_transformer.py:295] Using old attention computation from released December models.
I0710 15:02:26.396935 125989617137472 checkpointer.py:164] Restoring item from /home/yunqiliu/.cache/huggingface/hub/models--rail-berkeley--octo-small/snapshots/03d88976c54a58e10480d2043a8c762b35bc2611/270000/default.
I0710 15:02:27.050348 125989617137472 checkpointer.py:166] Finished restoring checkpoint from /home/yunqiliu/.cache/huggingface/hub/models--rail-berkeley--octo-small/snapshots/03d88976c54a58e10480d2043a8c762b35bc2611/270000/default.
/home/yunqiliu/anaconda3/envs/torch/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
I0710 15:02:28.617393 125989617137472 02_finetune_new_observation_action.py:69] Loading finetuning dataset...
I0710 15:02:28.623149 125989617137472 dataset_info.py:578] Load dataset info from /home/yunqiliu/tensorflow_datasets/aloha_sim_cube_scripted_dataset/1.0.0
I0710 15:02:28.706580 125989617137472 logging_logger.py:49] Constructing tf.data.Dataset aloha_sim_cube_scripted_dataset for split all, from /home/yunqiliu/tensorflow_datasets/aloha_sim_cube_scripted_dataset/1.0.0
This model is trained with a window size of 2, predicting 7 dimensional actions 4 steps into the future.
Observations and tasks conform to the following spec:
Observations: {
    image_primary: ('batch', 'history_window', 256, 256, 3),
    image_wrist: ('batch', 'history_window', 128, 128, 3),
}
Tasks: {
    image_primary: ('batch', 256, 256, 3),
    image_wrist: ('batch', 128, 128, 3),
    language_instruction: {
        attention_mask: ('batch', 16),
        input_ids: ('batch', 16),
    },
}
At inference, you may pass in any subset of these observation and task keys, with a history window up to 2 timesteps.
I0710 15:02:29.448291 125989617137472 function_wrappers.py:112] Sampling uniformly across keys: ['language_instruction']
I0710 15:02:29.674896 125989617137472 data_utils.py:113] Loading existing dataset statistics from /home/yunqiliu/tensorflow_datasets/aloha_sim_cube_scripted_dataset/1.0.0/dataset_statistics_6e9a30171a12844cc8c8c309ca19f52e9b09ba3dce8b5c743bb122a40baba07c.json.
I0710 15:02:29.715564 125989617137472 logging_logger.py:49] Constructing tf.data.Dataset aloha_sim_cube_scripted_dataset for split train[:95%], from /home/yunqiliu/tensorflow_datasets/aloha_sim_cube_scripted_dataset/1.0.0
I0710 15:02:29.770481 125989617137472 function_wrappers.py:112] Sampling uniformly across keys: ['language_instruction']
I0710 15:02:35.869796 125989617137472 02_finetune_new_observation_action.py:129] Updating model for new observation & action space...
I0710 15:02:37.017084 125989617137472 tokenizers.py:124] No task inputs matching image_primary were found. Replacing with zero padding.
[3m                                                        Attention Mask                                                         
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ[1m                                [22mâ”ƒ[1m task_language (16    [22mâ”ƒ[1m t=0 obs_primary (256 [22mâ”ƒ[1m t=0 obs_proprio (14   [22mâ”ƒ[1m t=0 readout_action   [22mâ”ƒ
â”ƒ[1m                                [22mâ”ƒ[1m tokens)              [22mâ”ƒ[1m tokens)              [22mâ”ƒ[1m tokens)               [22mâ”ƒ[1m (1 tokens)           [22mâ”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ task_language (16 tokens)      â”‚ x                    â”‚ x                    â”‚ x                     â”‚ x                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ t=0 obs_primary (256 tokens)   â”‚                      â”‚ x                    â”‚ x                     â”‚ x                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ t=0 obs_proprio (14 tokens)    â”‚                      â”‚ x                    â”‚ x                     â”‚ x                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ t=0 readout_action (1 tokens)  â”‚                      â”‚                      â”‚                       â”‚ x                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
W0710 15:02:37.152392 125989617137472 block_transformer.py:410] Prefix groups:
W0710 15:02:37.152678 125989617137472 block_transformer.py:412] PrefixGroup(name=task_language, shape=(1, 16, 384), attends_to={
    task_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
})
W0710 15:02:37.152774 125989617137472 block_transformer.py:418] Timestep groups:
W0710 15:02:37.152847 125989617137472 block_transformer.py:420] TimestepGroup(name=obs_primary, shape=(1, 1, 256, 384), attends_to={
    task_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
    obs_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
})
W0710 15:02:37.152932 125989617137472 block_transformer.py:420] TimestepGroup(name=obs_proprio, shape=(1, 1, 14, 384), attends_to={
    task_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
    obs_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
})
W0710 15:02:37.153012 125989617137472 block_transformer.py:420] TimestepGroup(name=readout_action, shape=(1, 1, 1, 384), attends_to={
    task_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
    obs_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
    readout_action: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
})
W0710 15:02:37.158056 125989617137472 block_transformer.py:295] Using old attention computation from released December models.
/home/yunqiliu/anaconda3/envs/torch/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[3m                                                      OctoModule Summary                                                       
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ[1m path                    [22mâ”ƒ[1m module                [22mâ”ƒ[1m inputs                 [22mâ”ƒ[1m outputs                 [22mâ”ƒ[1m params                 [22mâ”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚                         â”‚ OctoModule            â”‚ - image_primary:       â”‚ - obs:                  â”‚                        â”‚
â”‚                         â”‚                       â”‚ uint8[1,1,256,256,3]   â”‚     mask: bool[1,1,270] â”‚                        â”‚
â”‚                         â”‚                       â”‚   pad_mask_dict:       â”‚     tokens:             â”‚                        â”‚
â”‚                         â”‚                       â”‚     image_primary:     â”‚ float32[1,1,270,384]    â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1,1]              â”‚   obs_primary:          â”‚                        â”‚
â”‚                         â”‚                       â”‚     proprio: bool[1,1] â”‚     mask: bool[1,1,256] â”‚                        â”‚
â”‚                         â”‚                       â”‚     timestep:          â”‚     tokens:             â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1,1]              â”‚ float32[1,1,256,384]    â”‚                        â”‚
â”‚                         â”‚                       â”‚   proprio:             â”‚   obs_proprio:          â”‚                        â”‚
â”‚                         â”‚                       â”‚ float32[1,1,14]        â”‚     mask: bool[1,1,14]  â”‚                        â”‚
â”‚                         â”‚                       â”‚   task_completed:      â”‚     tokens:             â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1,1,50]           â”‚ float32[1,1,14,384]     â”‚                        â”‚
â”‚                         â”‚                       â”‚   timestep: int32[1,1] â”‚   readout_action:       â”‚                        â”‚
â”‚                         â”‚                       â”‚   timestep_pad_mask:   â”‚     mask:               â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1,1]              â”‚ float32[1,1,1]          â”‚                        â”‚
â”‚                         â”‚                       â”‚ -                      â”‚     tokens:             â”‚                        â”‚
â”‚                         â”‚                       â”‚ language_instruction:  â”‚ float32[1,1,1,384]      â”‚                        â”‚
â”‚                         â”‚                       â”‚     attention_mask:    â”‚   task:                 â”‚                        â”‚
â”‚                         â”‚                       â”‚ int32[1,16]            â”‚     mask: bool[1,16]    â”‚                        â”‚
â”‚                         â”‚                       â”‚     input_ids:         â”‚     tokens:             â”‚                        â”‚
â”‚                         â”‚                       â”‚ int32[1,16]            â”‚ float32[1,16,384]       â”‚                        â”‚
â”‚                         â”‚                       â”‚   pad_mask_dict:       â”‚   task_language:        â”‚                        â”‚
â”‚                         â”‚                       â”‚     language_instructâ€¦ â”‚     mask: bool[1,16]    â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1]                â”‚     tokens:             â”‚                        â”‚
â”‚                         â”‚                       â”‚ - bool[1,1]            â”‚ float32[1,16,384]       â”‚                        â”‚
â”‚                         â”‚                       â”‚ - train: False         â”‚ - action:               â”‚                        â”‚
â”‚                         â”‚                       â”‚   verbose: True        â”‚ float32[1,1,50,14]      â”‚                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transformer        â”‚ OctoTransformer       â”‚ - image_primary:       â”‚ obs:                    â”‚ obs_primary_pos_embedâ€¦ â”‚
â”‚                         â”‚                       â”‚ uint8[1,1,256,256,3]   â”‚   mask: bool[1,1,270]   â”‚ float32[1,10,256,384]  â”‚
â”‚                         â”‚                       â”‚   pad_mask_dict:       â”‚   tokens:               â”‚ obs_proprio_pos_embedâ€¦ â”‚
â”‚                         â”‚                       â”‚     image_primary:     â”‚ float32[1,1,270,384]    â”‚ float32[1,10,14,384]   â”‚
â”‚                         â”‚                       â”‚ bool[1,1]              â”‚ obs_primary:            â”‚ readout_action_pos_emâ€¦ â”‚
â”‚                         â”‚                       â”‚     proprio: bool[1,1] â”‚   mask: bool[1,1,256]   â”‚ float32[1,10,1,384]    â”‚
â”‚                         â”‚                       â”‚     timestep:          â”‚   tokens:               â”‚ task_language_pos_embâ€¦ â”‚
â”‚                         â”‚                       â”‚ bool[1,1]              â”‚ float32[1,1,256,384]    â”‚ float32[1,16,384]      â”‚
â”‚                         â”‚                       â”‚   proprio:             â”‚ obs_proprio:            â”‚                        â”‚
â”‚                         â”‚                       â”‚ float32[1,1,14]        â”‚   mask: bool[1,1,14]    â”‚ [1m1,046,784 (4.2 MB)[22m     â”‚
â”‚                         â”‚                       â”‚   task_completed:      â”‚   tokens:               â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1,1,50]           â”‚ float32[1,1,14,384]     â”‚                        â”‚
â”‚                         â”‚                       â”‚   timestep: int32[1,1] â”‚ readout_action:         â”‚                        â”‚
â”‚                         â”‚                       â”‚   timestep_pad_mask:   â”‚   mask: float32[1,1,1]  â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1,1]              â”‚   tokens:               â”‚                        â”‚
â”‚                         â”‚                       â”‚ -                      â”‚ float32[1,1,1,384]      â”‚                        â”‚
â”‚                         â”‚                       â”‚ language_instruction:  â”‚ task:                   â”‚                        â”‚
â”‚                         â”‚                       â”‚     attention_mask:    â”‚   mask: bool[1,16]      â”‚                        â”‚
â”‚                         â”‚                       â”‚ int32[1,16]            â”‚   tokens:               â”‚                        â”‚
â”‚                         â”‚                       â”‚     input_ids:         â”‚ float32[1,16,384]       â”‚                        â”‚
â”‚                         â”‚                       â”‚ int32[1,16]            â”‚ task_language:          â”‚                        â”‚
â”‚                         â”‚                       â”‚   pad_mask_dict:       â”‚   mask: bool[1,16]      â”‚                        â”‚
â”‚                         â”‚                       â”‚     language_instructâ€¦ â”‚   tokens:               â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1]                â”‚ float32[1,16,384]       â”‚                        â”‚
â”‚                         â”‚                       â”‚ - bool[1,1]            â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ - train: False         â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   verbose: True        â”‚                         â”‚                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ encoder                 â”‚ FlaxT5Stack           â”‚ attention_mask:        â”‚ attentions: None        â”‚                        â”‚
â”‚                         â”‚                       â”‚ int32[1,1]             â”‚ cross_attentions: None  â”‚                        â”‚
â”‚                         â”‚                       â”‚ deterministic: True    â”‚ hidden_states: None     â”‚                        â”‚
â”‚                         â”‚                       â”‚ input_ids: int32[1,1]  â”‚ last_hidden_state:      â”‚                        â”‚
â”‚                         â”‚                       â”‚ output_attentions:     â”‚ float32[1,1,768]        â”‚                        â”‚
â”‚                         â”‚                       â”‚ False                  â”‚ past_key_values: None   â”‚                        â”‚
â”‚                         â”‚                       â”‚ output_hidden_states:  â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ False                  â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ return_dict: True      â”‚                         â”‚                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ shared                  â”‚ Embed                 â”‚ int32[1,1]             â”‚ float32[1,1,768]        â”‚                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ encoder/dropout         â”‚ Dropout               â”‚ - float32[1,1,768]     â”‚ float32[1,1,768]        â”‚                        â”‚
â”‚                         â”‚                       â”‚ - deterministic: True  â”‚                         â”‚                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ encoder/block           â”‚ FlaxT5BlockCollection â”‚ - float32[1,1,768]     â”‚ attentions: None        â”‚                        â”‚
â”‚                         â”‚                       â”‚ - attention_mask:      â”‚ cross_attentions: None  â”‚                        â”‚
â”‚                         â”‚                       â”‚ int32[1,1]             â”‚ hidden_states: None     â”‚                        â”‚
â”‚                         â”‚                       â”‚   deterministic: True  â”‚ last_hidden_state:      â”‚                        â”‚
â”‚                         â”‚                       â”‚   encoder_attention_mâ€¦ â”‚ float32[1,1,768]        â”‚                        â”‚
â”‚                         â”‚                       â”‚ None                   â”‚ past_key_values: None   â”‚                        â”‚
â”‚                         â”‚                       â”‚   encoder_hidden_statâ€¦ â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ None                   â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   init_cache: False    â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   output_attentions:   â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ False                  â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   output_hidden_stateâ€¦ â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ False                  â”‚                         â”‚                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ encoder/final_layer_noâ€¦ â”‚ FlaxT5LayerNorm       â”‚ float32[1,1,768]       â”‚ float32[1,1,768]        â”‚                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transformer/task_â€¦ â”‚ LanguageTokenizer     â”‚ - image_primary:       â”‚ mask: bool[1,16]        â”‚ [1m109,628,544 (438.5 MB)[22m â”‚
â”‚                         â”‚                       â”‚ uint8[1,1,256,256,3]   â”‚ tokens:                 â”‚                        â”‚
â”‚                         â”‚                       â”‚   pad_mask_dict:       â”‚ float32[1,16,768]       â”‚                        â”‚
â”‚                         â”‚                       â”‚     image_primary:     â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1,1]              â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     proprio: bool[1,1] â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     timestep:          â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1,1]              â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   proprio:             â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ float32[1,1,14]        â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   task_completed:      â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1,1,50]           â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   timestep: int32[1,1] â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   timestep_pad_mask:   â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1,1]              â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ -                      â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ language_instruction:  â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     attention_mask:    â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ int32[1,16]            â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     input_ids:         â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ int32[1,16]            â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   pad_mask_dict:       â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     language_instructâ€¦ â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1]                â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ - train: False         â”‚                         â”‚                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transformer/task_â€¦ â”‚ Dense                 â”‚ float32[1,16,768]      â”‚ float32[1,16,384]       â”‚ bias: float32[384]     â”‚
â”‚                         â”‚                       â”‚                        â”‚                         â”‚ kernel:                â”‚
â”‚                         â”‚                       â”‚                        â”‚                         â”‚ float32[768,384]       â”‚
â”‚                         â”‚                       â”‚                        â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚                        â”‚                         â”‚ [1m295,296 (1.2 MB)[22m       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transformer/obserâ€¦ â”‚ ImageTokenizer        â”‚ - image_primary:       â”‚ mask: bool[1,1,256]     â”‚ [1m1,058,048 (4.2 MB)[22m     â”‚
â”‚                         â”‚                       â”‚ uint8[1,1,256,256,3]   â”‚ tokens:                 â”‚                        â”‚
â”‚                         â”‚                       â”‚   pad_mask_dict:       â”‚ float32[1,1,256,512]    â”‚                        â”‚
â”‚                         â”‚                       â”‚     image_primary:     â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1,1]              â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     proprio: bool[1,1] â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     timestep:          â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1,1]              â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   proprio:             â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ float32[1,1,14]        â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   task_completed:      â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1,1,50]           â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   timestep: int32[1,1] â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   timestep_pad_mask:   â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1,1]              â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ -                      â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ language_instruction:  â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     attention_mask:    â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ int32[1,16]            â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     input_ids:         â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ int32[1,16]            â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   pad_mask_dict:       â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     language_instructâ€¦ â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1]                â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ - train: False         â”‚                         â”‚                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transformer/obs_pâ€¦ â”‚ Dense                 â”‚ float32[1,1,256,512]   â”‚ float32[1,1,256,384]    â”‚ bias: float32[384]     â”‚
â”‚                         â”‚                       â”‚                        â”‚                         â”‚ kernel:                â”‚
â”‚                         â”‚                       â”‚                        â”‚                         â”‚ float32[512,384]       â”‚
â”‚                         â”‚                       â”‚                        â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚                        â”‚                         â”‚ [1m196,992 (788.0 KB)[22m     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transformer/obserâ€¦ â”‚ LowdimObsTokenizer    â”‚ - image_primary:       â”‚ mask: float32[1,1,14]   â”‚                        â”‚
â”‚                         â”‚                       â”‚ uint8[1,1,256,256,3]   â”‚ tokens:                 â”‚                        â”‚
â”‚                         â”‚                       â”‚   pad_mask_dict:       â”‚ float32[1,1,14,1]       â”‚                        â”‚
â”‚                         â”‚                       â”‚     image_primary:     â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1,1]              â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     proprio: bool[1,1] â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     timestep:          â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1,1]              â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   proprio:             â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ float32[1,1,14]        â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   task_completed:      â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1,1,50]           â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   timestep: int32[1,1] â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   timestep_pad_mask:   â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1,1]              â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ -                      â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ language_instruction:  â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     attention_mask:    â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ int32[1,16]            â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     input_ids:         â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ int32[1,16]            â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   pad_mask_dict:       â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     language_instructâ€¦ â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1]                â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ - train: False         â”‚                         â”‚                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transformer/obs_pâ€¦ â”‚ Dense                 â”‚ float32[1,1,14,1]      â”‚ float32[1,1,14,384]     â”‚ bias: float32[384]     â”‚
â”‚                         â”‚                       â”‚                        â”‚                         â”‚ kernel: float32[1,384] â”‚
â”‚                         â”‚                       â”‚                        â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚                        â”‚                         â”‚ [1m768 (3.1 KB)[22m           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transformer/Blockâ€¦ â”‚ BlockTransformer      â”‚ - - attention_rules:   â”‚ - - attention_rules:    â”‚ [1m21,294,336 (85.2 MB)[22m   â”‚
â”‚                         â”‚                       â”‚       task_*:          â”‚       task_*:           â”‚                        â”‚
â”‚                         â”‚                       â”‚ <AttentionRule.CAUSAL: â”‚ <AttentionRule.CAUSAL:  â”‚                        â”‚
â”‚                         â”‚                       â”‚ other.timestep <=      â”‚ other.timestep <=       â”‚                        â”‚
â”‚                         â”‚                       â”‚ self.timestep>         â”‚ self.timestep>          â”‚                        â”‚
â”‚                         â”‚                       â”‚     mask: bool[1,16]   â”‚     mask: bool[1,16]    â”‚                        â”‚
â”‚                         â”‚                       â”‚     name:              â”‚     name: task_language â”‚                        â”‚
â”‚                         â”‚                       â”‚ task_language          â”‚     tokens:             â”‚                        â”‚
â”‚                         â”‚                       â”‚     tokens:            â”‚ float32[1,16,384]       â”‚                        â”‚
â”‚                         â”‚                       â”‚ float32[1,16,384]      â”‚ - - attention_rules:    â”‚                        â”‚
â”‚                         â”‚                       â”‚ - - attention_rules:   â”‚       obs_*:            â”‚                        â”‚
â”‚                         â”‚                       â”‚       obs_*:           â”‚ <AttentionRule.CAUSAL:  â”‚                        â”‚
â”‚                         â”‚                       â”‚ <AttentionRule.CAUSAL: â”‚ other.timestep <=       â”‚                        â”‚
â”‚                         â”‚                       â”‚ other.timestep <=      â”‚ self.timestep>          â”‚                        â”‚
â”‚                         â”‚                       â”‚ self.timestep>         â”‚       task_*:           â”‚                        â”‚
â”‚                         â”‚                       â”‚       task_*:          â”‚ <AttentionRule.CAUSAL:  â”‚                        â”‚
â”‚                         â”‚                       â”‚ <AttentionRule.CAUSAL: â”‚ other.timestep <=       â”‚                        â”‚
â”‚                         â”‚                       â”‚ other.timestep <=      â”‚ self.timestep>          â”‚                        â”‚
â”‚                         â”‚                       â”‚ self.timestep>         â”‚     mask: bool[1,1,256] â”‚                        â”‚
â”‚                         â”‚                       â”‚     mask:              â”‚     name: obs_primary   â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1,1,256]          â”‚     tokens:             â”‚                        â”‚
â”‚                         â”‚                       â”‚     name: obs_primary  â”‚ float32[1,1,256,384]    â”‚                        â”‚
â”‚                         â”‚                       â”‚     tokens:            â”‚   - attention_rules:    â”‚                        â”‚
â”‚                         â”‚                       â”‚ float32[1,1,256,384]   â”‚       obs_*:            â”‚                        â”‚
â”‚                         â”‚                       â”‚   - attention_rules:   â”‚ <AttentionRule.CAUSAL:  â”‚                        â”‚
â”‚                         â”‚                       â”‚       obs_*:           â”‚ other.timestep <=       â”‚                        â”‚
â”‚                         â”‚                       â”‚ <AttentionRule.CAUSAL: â”‚ self.timestep>          â”‚                        â”‚
â”‚                         â”‚                       â”‚ other.timestep <=      â”‚       task_*:           â”‚                        â”‚
â”‚                         â”‚                       â”‚ self.timestep>         â”‚ <AttentionRule.CAUSAL:  â”‚                        â”‚
â”‚                         â”‚                       â”‚       task_*:          â”‚ other.timestep <=       â”‚                        â”‚
â”‚                         â”‚                       â”‚ <AttentionRule.CAUSAL: â”‚ self.timestep>          â”‚                        â”‚
â”‚                         â”‚                       â”‚ other.timestep <=      â”‚     mask: bool[1,1,14]  â”‚                        â”‚
â”‚                         â”‚                       â”‚ self.timestep>         â”‚     name: obs_proprio   â”‚                        â”‚
â”‚                         â”‚                       â”‚     mask: bool[1,1,14] â”‚     tokens:             â”‚                        â”‚
â”‚                         â”‚                       â”‚     name: obs_proprio  â”‚ float32[1,1,14,384]     â”‚                        â”‚
â”‚                         â”‚                       â”‚     tokens:            â”‚   - attention_rules:    â”‚                        â”‚
â”‚                         â”‚                       â”‚ float32[1,1,14,384]    â”‚       obs_*:            â”‚                        â”‚
â”‚                         â”‚                       â”‚   - attention_rules:   â”‚ <AttentionRule.CAUSAL:  â”‚                        â”‚
â”‚                         â”‚                       â”‚       obs_*:           â”‚ other.timestep <=       â”‚                        â”‚
â”‚                         â”‚                       â”‚ <AttentionRule.CAUSAL: â”‚ self.timestep>          â”‚                        â”‚
â”‚                         â”‚                       â”‚ other.timestep <=      â”‚       readout_action:   â”‚                        â”‚
â”‚                         â”‚                       â”‚ self.timestep>         â”‚ <AttentionRule.CAUSAL:  â”‚                        â”‚
â”‚                         â”‚                       â”‚       readout_action:  â”‚ other.timestep <=       â”‚                        â”‚
â”‚                         â”‚                       â”‚ <AttentionRule.CAUSAL: â”‚ self.timestep>          â”‚                        â”‚
â”‚                         â”‚                       â”‚ other.timestep <=      â”‚       task_*:           â”‚                        â”‚
â”‚                         â”‚                       â”‚ self.timestep>         â”‚ <AttentionRule.CAUSAL:  â”‚                        â”‚
â”‚                         â”‚                       â”‚       task_*:          â”‚ other.timestep <=       â”‚                        â”‚
â”‚                         â”‚                       â”‚ <AttentionRule.CAUSAL: â”‚ self.timestep>          â”‚                        â”‚
â”‚                         â”‚                       â”‚ other.timestep <=      â”‚     mask:               â”‚                        â”‚
â”‚                         â”‚                       â”‚ self.timestep>         â”‚ float32[1,1,1]          â”‚                        â”‚
â”‚                         â”‚                       â”‚     mask:              â”‚     name:               â”‚                        â”‚
â”‚                         â”‚                       â”‚ float32[1,1,1]         â”‚ readout_action          â”‚                        â”‚
â”‚                         â”‚                       â”‚     name:              â”‚     tokens:             â”‚                        â”‚
â”‚                         â”‚                       â”‚ readout_action         â”‚ float32[1,1,1,384]      â”‚                        â”‚
â”‚                         â”‚                       â”‚     tokens:            â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ float32[1,1,1,384]     â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ - train: False         â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   verbose: True        â”‚                         â”‚                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ heads_action            â”‚ L1ActionHead          â”‚ - obs:                 â”‚ float32[1,1,50,14]      â”‚                        â”‚
â”‚                         â”‚                       â”‚     mask:              â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1,1,270]          â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     tokens:            â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ float32[1,1,270,384]   â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   obs_primary:         â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     mask:              â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ bool[1,1,256]          â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     tokens:            â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ float32[1,1,256,384]   â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   obs_proprio:         â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     mask: bool[1,1,14] â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     tokens:            â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ float32[1,1,14,384]    â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   readout_action:      â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     mask:              â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ float32[1,1,1]         â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     tokens:            â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ float32[1,1,1,384]     â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   task:                â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     mask: bool[1,16]   â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     tokens:            â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ float32[1,16,384]      â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚   task_language:       â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     mask: bool[1,16]   â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚     tokens:            â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ float32[1,16,384]      â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ - train: False         â”‚                         â”‚                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ heads_action/map_head   â”‚ MAPHead               â”‚ - mask: float32[1,1,1] â”‚ float32[1,1,1,384]      â”‚ probe:                 â”‚
â”‚                         â”‚                       â”‚   tokens:              â”‚                         â”‚ float32[1,1,384]       â”‚
â”‚                         â”‚                       â”‚ float32[1,1,1,384]     â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚ - train: False         â”‚                         â”‚ [1m1,774,080 (7.1 MB)[22m     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ heads_action/mean_proj  â”‚ Dense                 â”‚ float32[1,1,384]       â”‚ float32[1,1,700]        â”‚ bias: float32[700]     â”‚
â”‚                         â”‚                       â”‚                        â”‚                         â”‚ kernel:                â”‚
â”‚                         â”‚                       â”‚                        â”‚                         â”‚ float32[384,700]       â”‚
â”‚                         â”‚                       â”‚                        â”‚                         â”‚                        â”‚
â”‚                         â”‚                       â”‚                        â”‚                         â”‚ [1m269,500 (1.1 MB)[22m       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚[1m                         [22mâ”‚[1m                       [22mâ”‚[1m                        [22mâ”‚[1m                   Total [22mâ”‚[1m 135,564,348 (542.3 MB) [22mâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
[1m                                                                                                                               
[1m                                           Total Parameters: 135,564,348 (542.3 MB)                                            
I0710 15:02:40.236520 125989617137472 tokenizers.py:124] No task inputs matching image_primary were found. Replacing with zero padding.
W0710 15:02:40.322632 125989617137472 block_transformer.py:295] Using old attention computation from released December models.
I0710 15:03:17.193377 125989617137472 train_utils.py:405] ########## Parameters skipped during model loading: ##########
I0710 15:03:17.193945 125989617137472 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.LayerNorm_0.bias
I0710 15:03:17.194041 125989617137472 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.LayerNorm_0.scale
I0710 15:03:17.194105 125989617137472 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MlpBlock_0.Dense_0.bias
I0710 15:03:17.194166 125989617137472 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MlpBlock_0.Dense_0.kernel
I0710 15:03:17.194223 125989617137472 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MlpBlock_0.Dense_1.bias
I0710 15:03:17.194278 125989617137472 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MlpBlock_0.Dense_1.kernel
I0710 15:03:17.194337 125989617137472 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MultiHeadDotProductAttention_0.key.bias
I0710 15:03:17.194392 125989617137472 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MultiHeadDotProductAttention_0.key.kernel
I0710 15:03:17.194448 125989617137472 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MultiHeadDotProductAttention_0.out.bias
I0710 15:03:17.194506 125989617137472 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MultiHeadDotProductAttention_0.out.kernel
I0710 15:03:17.194562 125989617137472 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MultiHeadDotProductAttention_0.query.bias
I0710 15:03:17.194618 125989617137472 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MultiHeadDotProductAttention_0.query.kernel
I0710 15:03:17.194679 125989617137472 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MultiHeadDotProductAttention_0.value.bias
I0710 15:03:17.194735 125989617137472 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MultiHeadDotProductAttention_0.value.kernel
I0710 15:03:17.194792 125989617137472 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.probe
I0710 15:03:17.194848 125989617137472 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.mean_proj.bias
I0710 15:03:17.194901 125989617137472 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.mean_proj.kernel
I0710 15:03:17.194954 125989617137472 train_utils.py:407] Param missing in pre-trained model, skipping: octo_transformer.obs_proprio_pos_embedding
I0710 15:03:17.195016 125989617137472 train_utils.py:407] Param missing in pre-trained model, skipping: octo_transformer.obs_proprio_projection.bias
I0710 15:03:17.195070 125989617137472 train_utils.py:407] Param missing in pre-trained model, skipping: octo_transformer.obs_proprio_projection.kernel
I0710 15:03:17.198917 125989617137472 train_utils.py:250] Freezing parameters that include the following keys: ['*hf_model*'].
I0710 15:03:17.203974 125989617137472 train_utils.py:286] Num trainable params: 25,935,804.
I0710 15:03:17.204103 125989617137472 train_utils.py:287] Num frozen params: 109,628,544.
I0710 15:03:17.204173 125989617137472 train_utils.py:288] To see a detailed list of frozen params, set logging level to DEBUG.
I0710 15:03:17.929952 125989617137472 02_finetune_new_observation_action.py:187] Starting finetuning...
  0%|                                                                                                 | 0/5000 [00:00<?, ?it/s]I0710 15:03:19.604328 125989617137472 tokenizers.py:124] No task inputs matching image_primary were found. Replacing with zero padding.
W0710 15:03:20.366376 125989617137472 block_transformer.py:295] Using old attention computation from released December models.













