I0710 15:55:33.390051 135460982499136 02_finetune_new_observation_action.py:59] Loading pre-trained model...
Fetching 8 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 24018.92it/s]
/home/yunqiliu/anaconda3/envs/torch/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
W0710 15:55:37.143767 135460982499136 block_transformer.py:295] Using old attention computation from released December models.
I0710 15:55:43.790688 135460982499136 checkpointer.py:164] Restoring item from /home/yunqiliu/.cache/huggingface/hub/models--rail-berkeley--octo-small/snapshots/03d88976c54a58e10480d2043a8c762b35bc2611/270000/default.
I0710 15:55:44.433576 135460982499136 checkpointer.py:166] Finished restoring checkpoint from /home/yunqiliu/.cache/huggingface/hub/models--rail-berkeley--octo-small/snapshots/03d88976c54a58e10480d2043a8c762b35bc2611/270000/default.
/home/yunqiliu/anaconda3/envs/torch/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
I0710 15:55:45.945927 135460982499136 02_finetune_new_observation_action.py:68] Loading finetuning dataset...
I0710 15:55:45.951794 135460982499136 dataset_info.py:578] Load dataset info from /home/yunqiliu/tensorflow_datasets/aloha_sim_cube_scripted_dataset/1.0.0
I0710 15:55:46.846988 135460982499136 logging_logger.py:49] Constructing tf.data.Dataset aloha_sim_cube_scripted_dataset for split all, from /home/yunqiliu/tensorflow_datasets/aloha_sim_cube_scripted_dataset/1.0.0
This model is trained with a window size of 2, predicting 7 dimensional actions 4 steps into the future.
Observations and tasks conform to the following spec:
Observations: {
    image_primary: ('batch', 'history_window', 256, 256, 3),
    image_wrist: ('batch', 'history_window', 128, 128, 3),
}
Tasks: {
    image_primary: ('batch', 256, 256, 3),
    image_wrist: ('batch', 128, 128, 3),
    language_instruction: {
        attention_mask: ('batch', 16),
        input_ids: ('batch', 16),
    },
}
At inference, you may pass in any subset of these observation and task keys, with a history window up to 2 timesteps.
I0710 15:55:47.548912 135460982499136 function_wrappers.py:112] Sampling uniformly across keys: ['language_instruction']
I0710 15:55:47.740691 135460982499136 data_utils.py:113] Loading existing dataset statistics from /home/yunqiliu/tensorflow_datasets/aloha_sim_cube_scripted_dataset/1.0.0/dataset_statistics_6e9a30171a12844cc8c8c309ca19f52e9b09ba3dce8b5c743bb122a40baba07c.json.
I0710 15:55:47.777811 135460982499136 logging_logger.py:49] Constructing tf.data.Dataset aloha_sim_cube_scripted_dataset for split train[:95%], from /home/yunqiliu/tensorflow_datasets/aloha_sim_cube_scripted_dataset/1.0.0
I0710 15:55:47.832562 135460982499136 function_wrappers.py:112] Sampling uniformly across keys: ['language_instruction']
I0710 15:55:56.140849 135460982499136 02_finetune_new_observation_action.py:128] Updating model for new observation & action space...
I0710 15:55:57.435651 135460982499136 tokenizers.py:124] No task inputs matching image_primary were found. Replacing with zero padding.
W0710 15:55:57.634769 135460982499136 block_transformer.py:410] Prefix groups:
W0710 15:55:57.635154 135460982499136 block_transformer.py:412] PrefixGroup(name=task_language, shape=(1, 16, 384), attends_to={
    task_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
})
W0710 15:55:57.635291 135460982499136 block_transformer.py:418] Timestep groups:
W0710 15:55:57.635422 135460982499136 block_transformer.py:420] TimestepGroup(name=obs_primary, shape=(1, 1, 256, 384), attends_to={
    task_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
    obs_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
})
W0710 15:55:57.635539 135460982499136 block_transformer.py:420] TimestepGroup(name=obs_proprio, shape=(1, 1, 14, 384), attends_to={
    task_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
    obs_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
})
W0710 15:55:57.635650 135460982499136 block_transformer.py:420] TimestepGroup(name=readout_action, shape=(1, 1, 1, 384), attends_to={
    task_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
    obs_*: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
    readout_action: <AttentionRule.CAUSAL: 'other.timestep <= self.timestep'>,
})
[3m                                                                        Attention Mask                                                                        
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ[1m                                [22mâ”ƒ[1m task_language (16 tokens) [22mâ”ƒ[1m t=0 obs_primary (256 tokens)  [22mâ”ƒ[1m t=0 obs_proprio (14 tokens)  [22mâ”ƒ[1m t=0 readout_action (1 tokens)  [22mâ”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ task_language (16 tokens)      â”‚ x                         â”‚ x                             â”‚ x                            â”‚ x                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ t=0 obs_primary (256 tokens)   â”‚                           â”‚ x                             â”‚ x                            â”‚ x                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ t=0 obs_proprio (14 tokens)    â”‚                           â”‚ x                             â”‚ x                            â”‚ x                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ t=0 readout_action (1 tokens)  â”‚                           â”‚                               â”‚                              â”‚ x                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
W0710 15:55:57.642319 135460982499136 block_transformer.py:295] Using old attention computation from released December models.
/home/yunqiliu/anaconda3/envs/torch/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[3m                                                                        OctoModule Summary                                                                        
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ[1m path                            [22mâ”ƒ[1m module                [22mâ”ƒ[1m inputs                          [22mâ”ƒ[1m outputs                         [22mâ”ƒ[1m params                           [22mâ”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚                                 â”‚ OctoModule            â”‚ - image_primary:                â”‚ - obs:                          â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ uint8[1,1,256,256,3]            â”‚     mask: bool[1,1,270]         â”‚                                  â”‚
â”‚                                 â”‚                       â”‚   pad_mask_dict:                â”‚     tokens:                     â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     image_primary: bool[1,1]    â”‚ float32[1,1,270,384]            â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     proprio: bool[1,1]          â”‚   obs_primary:                  â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     timestep: bool[1,1]         â”‚     mask: bool[1,1,256]         â”‚                                  â”‚
â”‚                                 â”‚                       â”‚   proprio: float32[1,1,14]      â”‚     tokens:                     â”‚                                  â”‚
â”‚                                 â”‚                       â”‚   task_completed: bool[1,1,50]  â”‚ float32[1,1,256,384]            â”‚                                  â”‚
â”‚                                 â”‚                       â”‚   timestep: int32[1,1]          â”‚   obs_proprio:                  â”‚                                  â”‚
â”‚                                 â”‚                       â”‚   timestep_pad_mask: bool[1,1]  â”‚     mask: bool[1,1,14]          â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ - language_instruction:         â”‚     tokens: float32[1,1,14,384] â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     attention_mask: int32[1,16] â”‚   readout_action:               â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     input_ids: int32[1,16]      â”‚     mask: float32[1,1,1]        â”‚                                  â”‚
â”‚                                 â”‚                       â”‚   pad_mask_dict:                â”‚     tokens: float32[1,1,1,384]  â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     language_instruction:       â”‚   task:                         â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ bool[1]                         â”‚     mask: bool[1,16]            â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ - bool[1,1]                     â”‚     tokens: float32[1,16,384]   â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ - train: False                  â”‚   task_language:                â”‚                                  â”‚
â”‚                                 â”‚                       â”‚   verbose: True                 â”‚     mask: bool[1,16]            â”‚                                  â”‚
â”‚                                 â”‚                       â”‚                                 â”‚     tokens: float32[1,16,384]   â”‚                                  â”‚
â”‚                                 â”‚                       â”‚                                 â”‚ - action: float32[1,1,50,14]    â”‚                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transformer                â”‚ OctoTransformer       â”‚ - image_primary:                â”‚ obs:                            â”‚ obs_primary_pos_embedding:       â”‚
â”‚                                 â”‚                       â”‚ uint8[1,1,256,256,3]            â”‚   mask: bool[1,1,270]           â”‚ float32[1,10,256,384]            â”‚
â”‚                                 â”‚                       â”‚   pad_mask_dict:                â”‚   tokens: float32[1,1,270,384]  â”‚ obs_proprio_pos_embedding:       â”‚
â”‚                                 â”‚                       â”‚     image_primary: bool[1,1]    â”‚ obs_primary:                    â”‚ float32[1,10,14,384]             â”‚
â”‚                                 â”‚                       â”‚     proprio: bool[1,1]          â”‚   mask: bool[1,1,256]           â”‚ readout_action_pos_embedding:    â”‚
â”‚                                 â”‚                       â”‚     timestep: bool[1,1]         â”‚   tokens: float32[1,1,256,384]  â”‚ float32[1,10,1,384]              â”‚
â”‚                                 â”‚                       â”‚   proprio: float32[1,1,14]      â”‚ obs_proprio:                    â”‚ task_language_pos_embedding:     â”‚
â”‚                                 â”‚                       â”‚   task_completed: bool[1,1,50]  â”‚   mask: bool[1,1,14]            â”‚ float32[1,16,384]                â”‚
â”‚                                 â”‚                       â”‚   timestep: int32[1,1]          â”‚   tokens: float32[1,1,14,384]   â”‚                                  â”‚
â”‚                                 â”‚                       â”‚   timestep_pad_mask: bool[1,1]  â”‚ readout_action:                 â”‚ [1m1,046,784 (4.2 MB)[22m               â”‚
â”‚                                 â”‚                       â”‚ - language_instruction:         â”‚   mask: float32[1,1,1]          â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     attention_mask: int32[1,16] â”‚   tokens: float32[1,1,1,384]    â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     input_ids: int32[1,16]      â”‚ task:                           â”‚                                  â”‚
â”‚                                 â”‚                       â”‚   pad_mask_dict:                â”‚   mask: bool[1,16]              â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     language_instruction:       â”‚   tokens: float32[1,16,384]     â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ bool[1]                         â”‚ task_language:                  â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ - bool[1,1]                     â”‚   mask: bool[1,16]              â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ - train: False                  â”‚   tokens: float32[1,16,384]     â”‚                                  â”‚
â”‚                                 â”‚                       â”‚   verbose: True                 â”‚                                 â”‚                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ encoder                         â”‚ FlaxT5Stack           â”‚ attention_mask: int32[1,1]      â”‚ attentions: None                â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ deterministic: True             â”‚ cross_attentions: None          â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ input_ids: int32[1,1]           â”‚ hidden_states: None             â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ output_attentions: False        â”‚ last_hidden_state:              â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ output_hidden_states: False     â”‚ float32[1,1,768]                â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ return_dict: True               â”‚ past_key_values: None           â”‚                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ shared                          â”‚ Embed                 â”‚ int32[1,1]                      â”‚ float32[1,1,768]                â”‚                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ encoder/dropout                 â”‚ Dropout               â”‚ - float32[1,1,768]              â”‚ float32[1,1,768]                â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ - deterministic: True           â”‚                                 â”‚                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ encoder/block                   â”‚ FlaxT5BlockCollection â”‚ - float32[1,1,768]              â”‚ attentions: None                â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ - attention_mask: int32[1,1]    â”‚ cross_attentions: None          â”‚                                  â”‚
â”‚                                 â”‚                       â”‚   deterministic: True           â”‚ hidden_states: None             â”‚                                  â”‚
â”‚                                 â”‚                       â”‚   encoder_attention_mask: None  â”‚ last_hidden_state:              â”‚                                  â”‚
â”‚                                 â”‚                       â”‚   encoder_hidden_states: None   â”‚ float32[1,1,768]                â”‚                                  â”‚
â”‚                                 â”‚                       â”‚   init_cache: False             â”‚ past_key_values: None           â”‚                                  â”‚
â”‚                                 â”‚                       â”‚   output_attentions: False      â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚   output_hidden_states: False   â”‚                                 â”‚                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ encoder/final_layer_norm        â”‚ FlaxT5LayerNorm       â”‚ float32[1,1,768]                â”‚ float32[1,1,768]                â”‚                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transformer/task_tokenizeâ€¦ â”‚ LanguageTokenizer     â”‚ - image_primary:                â”‚ mask: bool[1,16]                â”‚ [1m109,628,544 (438.5 MB)[22m           â”‚
â”‚                                 â”‚                       â”‚ uint8[1,1,256,256,3]            â”‚ tokens: float32[1,16,768]       â”‚                                  â”‚
â”‚                                 â”‚                       â”‚   pad_mask_dict:                â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     image_primary: bool[1,1]    â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     proprio: bool[1,1]          â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     timestep: bool[1,1]         â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚   proprio: float32[1,1,14]      â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚   task_completed: bool[1,1,50]  â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚   timestep: int32[1,1]          â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚   timestep_pad_mask: bool[1,1]  â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ - language_instruction:         â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     attention_mask: int32[1,16] â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     input_ids: int32[1,16]      â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚   pad_mask_dict:                â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     language_instruction:       â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ bool[1]                         â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ - train: False                  â”‚                                 â”‚                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transformer/task_languageâ€¦ â”‚ Dense                 â”‚ float32[1,16,768]               â”‚ float32[1,16,384]               â”‚ bias: float32[384]               â”‚
â”‚                                 â”‚                       â”‚                                 â”‚                                 â”‚ kernel: float32[768,384]         â”‚
â”‚                                 â”‚                       â”‚                                 â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚                                 â”‚                                 â”‚ [1m295,296 (1.2 MB)[22m                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transformer/observation_tâ€¦ â”‚ ImageTokenizer        â”‚ - image_primary:                â”‚ mask: bool[1,1,256]             â”‚ [1m1,058,048 (4.2 MB)[22m               â”‚
â”‚                                 â”‚                       â”‚ uint8[1,1,256,256,3]            â”‚ tokens: float32[1,1,256,512]    â”‚                                  â”‚
â”‚                                 â”‚                       â”‚   pad_mask_dict:                â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     image_primary: bool[1,1]    â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     proprio: bool[1,1]          â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     timestep: bool[1,1]         â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚   proprio: float32[1,1,14]      â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚   task_completed: bool[1,1,50]  â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚   timestep: int32[1,1]          â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚   timestep_pad_mask: bool[1,1]  â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ - language_instruction:         â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     attention_mask: int32[1,16] â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     input_ids: int32[1,16]      â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚   pad_mask_dict:                â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     language_instruction:       â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ bool[1]                         â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ - train: False                  â”‚                                 â”‚                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transformer/obs_primary_pâ€¦ â”‚ Dense                 â”‚ float32[1,1,256,512]            â”‚ float32[1,1,256,384]            â”‚ bias: float32[384]               â”‚
â”‚                                 â”‚                       â”‚                                 â”‚                                 â”‚ kernel: float32[512,384]         â”‚
â”‚                                 â”‚                       â”‚                                 â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚                                 â”‚                                 â”‚ [1m196,992 (788.0 KB)[22m               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transformer/observation_tâ€¦ â”‚ LowdimObsTokenizer    â”‚ - image_primary:                â”‚ mask: float32[1,1,14]           â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ uint8[1,1,256,256,3]            â”‚ tokens: float32[1,1,14,1]       â”‚                                  â”‚
â”‚                                 â”‚                       â”‚   pad_mask_dict:                â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     image_primary: bool[1,1]    â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     proprio: bool[1,1]          â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     timestep: bool[1,1]         â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚   proprio: float32[1,1,14]      â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚   task_completed: bool[1,1,50]  â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚   timestep: int32[1,1]          â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚   timestep_pad_mask: bool[1,1]  â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ - language_instruction:         â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     attention_mask: int32[1,16] â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     input_ids: int32[1,16]      â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚   pad_mask_dict:                â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     language_instruction:       â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ bool[1]                         â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ - train: False                  â”‚                                 â”‚                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transformer/obs_proprio_pâ€¦ â”‚ Dense                 â”‚ float32[1,1,14,1]               â”‚ float32[1,1,14,384]             â”‚ bias: float32[384]               â”‚
â”‚                                 â”‚                       â”‚                                 â”‚                                 â”‚ kernel: float32[1,384]           â”‚
â”‚                                 â”‚                       â”‚                                 â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚                                 â”‚                                 â”‚ [1m768 (3.1 KB)[22m                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ octo_transformer/BlockTransforâ€¦ â”‚ BlockTransformer      â”‚ - - attention_rules:            â”‚ - - attention_rules:            â”‚ [1m21,294,336 (85.2 MB)[22m             â”‚
â”‚                                 â”‚                       â”‚       task_*:                   â”‚       task_*:                   â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ <AttentionRule.CAUSAL:          â”‚ <AttentionRule.CAUSAL:          â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ other.timestep <=               â”‚ other.timestep <=               â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ self.timestep>                  â”‚ self.timestep>                  â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     mask: bool[1,16]            â”‚     mask: bool[1,16]            â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     name: task_language         â”‚     name: task_language         â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     tokens: float32[1,16,384]   â”‚     tokens: float32[1,16,384]   â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ - - attention_rules:            â”‚ - - attention_rules:            â”‚                                  â”‚
â”‚                                 â”‚                       â”‚       obs_*:                    â”‚       obs_*:                    â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ <AttentionRule.CAUSAL:          â”‚ <AttentionRule.CAUSAL:          â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ other.timestep <=               â”‚ other.timestep <=               â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ self.timestep>                  â”‚ self.timestep>                  â”‚                                  â”‚
â”‚                                 â”‚                       â”‚       task_*:                   â”‚       task_*:                   â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ <AttentionRule.CAUSAL:          â”‚ <AttentionRule.CAUSAL:          â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ other.timestep <=               â”‚ other.timestep <=               â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ self.timestep>                  â”‚ self.timestep>                  â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     mask: bool[1,1,256]         â”‚     mask: bool[1,1,256]         â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     name: obs_primary           â”‚     name: obs_primary           â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     tokens:                     â”‚     tokens:                     â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ float32[1,1,256,384]            â”‚ float32[1,1,256,384]            â”‚                                  â”‚
â”‚                                 â”‚                       â”‚   - attention_rules:            â”‚   - attention_rules:            â”‚                                  â”‚
â”‚                                 â”‚                       â”‚       obs_*:                    â”‚       obs_*:                    â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ <AttentionRule.CAUSAL:          â”‚ <AttentionRule.CAUSAL:          â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ other.timestep <=               â”‚ other.timestep <=               â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ self.timestep>                  â”‚ self.timestep>                  â”‚                                  â”‚
â”‚                                 â”‚                       â”‚       task_*:                   â”‚       task_*:                   â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ <AttentionRule.CAUSAL:          â”‚ <AttentionRule.CAUSAL:          â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ other.timestep <=               â”‚ other.timestep <=               â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ self.timestep>                  â”‚ self.timestep>                  â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     mask: bool[1,1,14]          â”‚     mask: bool[1,1,14]          â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     name: obs_proprio           â”‚     name: obs_proprio           â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     tokens: float32[1,1,14,384] â”‚     tokens: float32[1,1,14,384] â”‚                                  â”‚
â”‚                                 â”‚                       â”‚   - attention_rules:            â”‚   - attention_rules:            â”‚                                  â”‚
â”‚                                 â”‚                       â”‚       obs_*:                    â”‚       obs_*:                    â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ <AttentionRule.CAUSAL:          â”‚ <AttentionRule.CAUSAL:          â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ other.timestep <=               â”‚ other.timestep <=               â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ self.timestep>                  â”‚ self.timestep>                  â”‚                                  â”‚
â”‚                                 â”‚                       â”‚       readout_action:           â”‚       readout_action:           â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ <AttentionRule.CAUSAL:          â”‚ <AttentionRule.CAUSAL:          â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ other.timestep <=               â”‚ other.timestep <=               â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ self.timestep>                  â”‚ self.timestep>                  â”‚                                  â”‚
â”‚                                 â”‚                       â”‚       task_*:                   â”‚       task_*:                   â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ <AttentionRule.CAUSAL:          â”‚ <AttentionRule.CAUSAL:          â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ other.timestep <=               â”‚ other.timestep <=               â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ self.timestep>                  â”‚ self.timestep>                  â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     mask: float32[1,1,1]        â”‚     mask: float32[1,1,1]        â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     name: readout_action        â”‚     name: readout_action        â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     tokens: float32[1,1,1,384]  â”‚     tokens: float32[1,1,1,384]  â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ - train: False                  â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚   verbose: True                 â”‚                                 â”‚                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ heads_action                    â”‚ L1ActionHead          â”‚ - obs:                          â”‚ float32[1,1,50,14]              â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     mask: bool[1,1,270]         â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     tokens:                     â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ float32[1,1,270,384]            â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚   obs_primary:                  â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     mask: bool[1,1,256]         â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     tokens:                     â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ float32[1,1,256,384]            â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚   obs_proprio:                  â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     mask: bool[1,1,14]          â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     tokens: float32[1,1,14,384] â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚   readout_action:               â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     mask: float32[1,1,1]        â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     tokens: float32[1,1,1,384]  â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚   task:                         â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     mask: bool[1,16]            â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     tokens: float32[1,16,384]   â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚   task_language:                â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     mask: bool[1,16]            â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚     tokens: float32[1,16,384]   â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ - train: False                  â”‚                                 â”‚                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ heads_action/map_head           â”‚ MAPHead               â”‚ - mask: float32[1,1,1]          â”‚ float32[1,1,1,384]              â”‚ probe: float32[1,1,384]          â”‚
â”‚                                 â”‚                       â”‚   tokens: float32[1,1,1,384]    â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚ - train: False                  â”‚                                 â”‚ [1m1,774,080 (7.1 MB)[22m               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ heads_action/mean_proj          â”‚ Dense                 â”‚ float32[1,1,384]                â”‚ float32[1,1,700]                â”‚ bias: float32[700]               â”‚
â”‚                                 â”‚                       â”‚                                 â”‚                                 â”‚ kernel: float32[384,700]         â”‚
â”‚                                 â”‚                       â”‚                                 â”‚                                 â”‚                                  â”‚
â”‚                                 â”‚                       â”‚                                 â”‚                                 â”‚ [1m269,500 (1.1 MB)[22m                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚[1m                                 [22mâ”‚[1m                       [22mâ”‚[1m                                 [22mâ”‚[1m                           Total [22mâ”‚[1m 135,564,348 (542.3 MB)           [22mâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
[1m                                                                                                                                                                  
[1m                                                             Total Parameters: 135,564,348 (542.3 MB)                                                             
I0710 15:56:01.664123 135460982499136 tokenizers.py:124] No task inputs matching image_primary were found. Replacing with zero padding.
W0710 15:56:01.789132 135460982499136 block_transformer.py:295] Using old attention computation from released December models.
I0710 15:56:38.636192 135460982499136 train_utils.py:405] ########## Parameters skipped during model loading: ##########
I0710 15:56:38.636617 135460982499136 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.LayerNorm_0.bias
I0710 15:56:38.636696 135460982499136 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.LayerNorm_0.scale
I0710 15:56:38.636744 135460982499136 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MlpBlock_0.Dense_0.bias
I0710 15:56:38.636790 135460982499136 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MlpBlock_0.Dense_0.kernel
I0710 15:56:38.636834 135460982499136 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MlpBlock_0.Dense_1.bias
I0710 15:56:38.636876 135460982499136 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MlpBlock_0.Dense_1.kernel
I0710 15:56:38.636921 135460982499136 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MultiHeadDotProductAttention_0.key.bias
I0710 15:56:38.636965 135460982499136 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MultiHeadDotProductAttention_0.key.kernel
I0710 15:56:38.637009 135460982499136 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MultiHeadDotProductAttention_0.out.bias
I0710 15:56:38.637051 135460982499136 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MultiHeadDotProductAttention_0.out.kernel
I0710 15:56:38.637094 135460982499136 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MultiHeadDotProductAttention_0.query.bias
I0710 15:56:38.637139 135460982499136 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MultiHeadDotProductAttention_0.query.kernel
I0710 15:56:38.637183 135460982499136 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MultiHeadDotProductAttention_0.value.bias
I0710 15:56:38.637225 135460982499136 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.MultiHeadDotProductAttention_0.value.kernel
I0710 15:56:38.637272 135460982499136 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.map_head.probe
I0710 15:56:38.637316 135460982499136 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.mean_proj.bias
I0710 15:56:38.637361 135460982499136 train_utils.py:407] Param missing in pre-trained model, skipping: heads_action.mean_proj.kernel
I0710 15:56:38.637402 135460982499136 train_utils.py:407] Param missing in pre-trained model, skipping: octo_transformer.obs_proprio_pos_embedding
I0710 15:56:38.637446 135460982499136 train_utils.py:407] Param missing in pre-trained model, skipping: octo_transformer.obs_proprio_projection.bias
I0710 15:56:38.637488 135460982499136 train_utils.py:407] Param missing in pre-trained model, skipping: octo_transformer.obs_proprio_projection.kernel
I0710 15:56:38.653193 135460982499136 train_utils.py:250] Freezing parameters that include the following keys: ['*hf_model*'].
I0710 15:56:38.656830 135460982499136 train_utils.py:286] Num trainable params: 25,935,804.
I0710 15:56:38.656934 135460982499136 train_utils.py:287] Num frozen params: 109,628,544.
I0710 15:56:38.656989 135460982499136 train_utils.py:288] To see a detailed list of frozen params, set logging level to DEBUG.
I0710 15:56:39.094842 135460982499136 02_finetune_new_observation_action.py:186] Starting finetuning...
  0%|                                                                                                                    | 0/5000 [00:00<?, ?it/s]I0710 15:56:40.578148 135460982499136 tokenizers.py:124] No task inputs matching image_primary were found. Replacing with zero padding.
W0710 15:56:40.787113 135460982499136 block_transformer.py:295] Using old attention computation from released December models.








































