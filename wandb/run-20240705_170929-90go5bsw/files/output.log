

Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.33it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
finish loading the model
try loading some data for initialization
finish loading the data for initialization
metadata is dict_keys(['task_description', 'scene_description', 'mean', 'std', 'frame_number', 'image_indices', 'image_paths', 'actions', 'clip_description', 'trajectory_id', 'view'])
env=gym.make.....
obs, info = env.reset()
iteration starts: we will sample actions
start sampling actions
call model in sample actions function
finish calling
/home/yunqiliu/anaconda3/envs/torch/lib/python3.11/site-packages/gym/spaces/box.py:127: UserWarning: [33mWARN: Box bound precision lowered by casting to float32
  logger.warn(f"Box bound precision lowered by casting to {self.dtype}")
/home/yunqiliu/anaconda3/envs/torch/lib/python3.11/site-packages/gym/utils/passive_env_checker.py:137: UserWarning: [33mWARN: The obs returned by the `reset()` method was expecting a numpy array, actual type: <class 'tensorflow.python.framework.ops.EagerTensor'>
  logger.warn(
/home/yunqiliu/anaconda3/envs/torch/lib/python3.11/site-packages/gym/spaces/box.py:227: UserWarning: [33mWARN: Casting input x to numpy array.
  logger.warn("Casting input x to numpy array.")
/home/yunqiliu/anaconda3/envs/torch/lib/python3.11/site-packages/gym/utils/passive_env_checker.py:137: UserWarning: [33mWARN: The obs returned by the `reset()` method was expecting a numpy array, actual type: <class 'jaxlib.xla_extension.ArrayImpl'>
  logger.warn(
/home/yunqiliu/anaconda3/envs/torch/lib/python3.11/site-packages/gym/utils/passive_env_checker.py:165: UserWarning: [33mWARN: The obs returned by the `reset()` method is not within the observation space.
  logger.warn(f"{pre} is not within the observation space.")
/home/yunqiliu/anaconda3/envs/torch/lib/python3.11/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/home/yunqiliu/anaconda3/envs/torch/lib/python3.11/site-packages/gym/utils/passive_env_checker.py:137: UserWarning: [33mWARN: The obs returned by the `step()` method was expecting a numpy array, actual type: <class 'tensorflow.python.framework.ops.EagerTensor'>
  logger.warn(
/home/yunqiliu/anaconda3/envs/torch/lib/python3.11/site-packages/gym/utils/passive_env_checker.py:137: UserWarning: [33mWARN: The obs returned by the `step()` method was expecting a numpy array, actual type: <class 'jaxlib.xla_extension.ArrayImpl'>
  logger.warn(
let's see the output and actions: dict_keys(['pred_actions']) [[0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0]]
finish sampling actions
the shape of torch.tensor(info['observations']['image_primary']) is: (256, 256, 3)
iteration starts: we will sample actions
start sampling actions
call model in sample actions function
finish calling
let's see the output and actions: dict_keys(['pred_actions']) [[0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0]]
finish sampling actions
the shape of torch.tensor(info['observations']['image_primary']) is: (256, 256, 3)
iteration starts: we will sample actions
start sampling actions
call model in sample actions function
finish calling
let's see the output and actions: dict_keys(['pred_actions']) [[0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0]]
finish sampling actions
the shape of torch.tensor(info['observations']['image_primary']) is: (256, 256, 3)
iteration starts: we will sample actions
start sampling actions
call model in sample actions function
finish calling
let's see the output and actions: dict_keys(['pred_actions']) [[0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0]]
finish sampling actions
the shape of torch.tensor(info['observations']['image_primary']) is: (256, 256, 3)
iteration starts: we will sample actions
start sampling actions
call model in sample actions function
finish calling
let's see the output and actions: dict_keys(['pred_actions']) [[0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0]]
finish sampling actions
the shape of torch.tensor(info['observations']['image_primary']) is: (256, 256, 3)
iteration starts: we will sample actions
start sampling actions
call model in sample actions function
finish calling
let's see the output and actions: dict_keys(['pred_actions']) [[0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0]]
finish sampling actions
the shape of torch.tensor(info['observations']['image_primary']) is: (256, 256, 3)
iteration starts: we will sample actions
start sampling actions
call model in sample actions function
finish calling
let's see the output and actions: dict_keys(['pred_actions']) [[0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0]]
finish sampling actions
the shape of torch.tensor(info['observations']['image_primary']) is: (256, 256, 3)
iteration starts: we will sample actions
start sampling actions
call model in sample actions function
finish calling
let's see the output and actions: dict_keys(['pred_actions']) [[0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0]]
finish sampling actions
the shape of torch.tensor(info['observations']['image_primary']) is: (256, 256, 3)
iteration starts: we will sample actions
start sampling actions
call model in sample actions function
finish calling
let's see the output and actions: dict_keys(['pred_actions']) [[0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0]]
finish sampling actions
the shape of torch.tensor(info['observations']['image_primary']) is: (256, 256, 3)
iteration starts: we will sample actions
start sampling actions
call model in sample actions function
finish calling
let's see the output and actions: dict_keys(['pred_actions']) [[0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0]]
finish sampling actions
the shape of torch.tensor(info['observations']['image_primary']) is: (256, 256, 3)
Episode return: 0.0
the shape: (10, 256, 256, 3)
obs, info = env.reset()
iteration starts: we will sample actions
start sampling actions
call model in sample actions function
finish calling
let's see the output and actions: dict_keys(['pred_actions']) [[0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0]]
finish sampling actions
the shape of torch.tensor(info['observations']['image_primary']) is: (256, 256, 3)
iteration starts: we will sample actions
start sampling actions
call model in sample actions function
finish calling
let's see the output and actions: dict_keys(['pred_actions']) [[0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0]]
finish sampling actions
the shape of torch.tensor(info['observations']['image_primary']) is: (256, 256, 3)
iteration starts: we will sample actions
start sampling actions
call model in sample actions function
finish calling
let's see the output and actions: dict_keys(['pred_actions']) [[0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0]]
finish sampling actions
the shape of torch.tensor(info['observations']['image_primary']) is: (256, 256, 3)
iteration starts: we will sample actions
start sampling actions
call model in sample actions function
finish calling
let's see the output and actions: dict_keys(['pred_actions']) [[0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0]]
finish sampling actions
the shape of torch.tensor(info['observations']['image_primary']) is: (256, 256, 3)
iteration starts: we will sample actions
start sampling actions
call model in sample actions function
finish calling
let's see the output and actions: dict_keys(['pred_actions']) [[0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0]]
finish sampling actions
the shape of torch.tensor(info['observations']['image_primary']) is: (256, 256, 3)
iteration starts: we will sample actions
start sampling actions
call model in sample actions function
finish calling
let's see the output and actions: dict_keys(['pred_actions']) [[0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0]]
finish sampling actions
the shape of torch.tensor(info['observations']['image_primary']) is: (256, 256, 3)
iteration starts: we will sample actions
start sampling actions
call model in sample actions function
finish calling
let's see the output and actions: dict_keys(['pred_actions']) [[0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0]]
finish sampling actions
the shape of torch.tensor(info['observations']['image_primary']) is: (256, 256, 3)
iteration starts: we will sample actions
start sampling actions
call model in sample actions function
finish calling
let's see the output and actions: dict_keys(['pred_actions']) [[0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0]]
finish sampling actions
the shape of torch.tensor(info['observations']['image_primary']) is: (256, 256, 3)
iteration starts: we will sample actions
start sampling actions
call model in sample actions function
finish calling
let's see the output and actions: dict_keys(['pred_actions']) [[0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0]]
finish sampling actions
the shape of torch.tensor(info['observations']['image_primary']) is: (256, 256, 3)
iteration starts: we will sample actions
start sampling actions
call model in sample actions function
finish calling
let's see the output and actions: dict_keys(['pred_actions']) [[0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0]]
finish sampling actions
the shape of torch.tensor(info['observations']['image_primary']) is: (256, 256, 3)
Episode return: 0.0
the shape: (10, 256, 256, 3)
obs, info = env.reset()
iteration starts: we will sample actions
start sampling actions
call model in sample actions function
finish calling
let's see the output and actions: dict_keys(['pred_actions']) [[0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0]]
finish sampling actions
the shape of torch.tensor(info['observations']['image_primary']) is: (256, 256, 3)
iteration starts: we will sample actions
start sampling actions
call model in sample actions function
finish calling
let's see the output and actions: dict_keys(['pred_actions']) [[0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0]]
finish sampling actions
the shape of torch.tensor(info['observations']['image_primary']) is: (256, 256, 3)
iteration starts: we will sample actions
start sampling actions
call model in sample actions function
finish calling
let's see the output and actions: dict_keys(['pred_actions']) [[0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0]]
finish sampling actions
the shape of torch.tensor(info['observations']['image_primary']) is: (256, 256, 3)
iteration starts: we will sample actions
start sampling actions
call model in sample actions function
finish calling
let's see the output and actions: dict_keys(['pred_actions']) [[0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0]]
finish sampling actions
the shape of torch.tensor(info['observations']['image_primary']) is: (256, 256, 3)
iteration starts: we will sample actions
start sampling actions
call model in sample actions function
finish calling
let's see the output and actions: dict_keys(['pred_actions']) [[0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0]]
finish sampling actions
the shape of torch.tensor(info['observations']['image_primary']) is: (256, 256, 3)
iteration starts: we will sample actions
start sampling actions
call model in sample actions function
finish calling
let's see the output and actions: dict_keys(['pred_actions']) [[0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0]]
finish sampling actions
the shape of torch.tensor(info['observations']['image_primary']) is: (256, 256, 3)
iteration starts: we will sample actions
start sampling actions
call model in sample actions function
finish calling
let's see the output and actions: dict_keys(['pred_actions']) [[0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0]]
finish sampling actions
the shape of torch.tensor(info['observations']['image_primary']) is: (256, 256, 3)
iteration starts: we will sample actions
start sampling actions
call model in sample actions function
finish calling
let's see the output and actions: dict_keys(['pred_actions']) [[0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0]]
finish sampling actions
the shape of torch.tensor(info['observations']['image_primary']) is: (256, 256, 3)
iteration starts: we will sample actions
start sampling actions
call model in sample actions function
finish calling
let's see the output and actions: dict_keys(['pred_actions']) [[0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0]]
finish sampling actions
the shape of torch.tensor(info['observations']['image_primary']) is: (256, 256, 3)
iteration starts: we will sample actions
start sampling actions
call model in sample actions function
finish calling
let's see the output and actions: dict_keys(['pred_actions']) [[0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0], [0.0005728628020733595, 0.000131971639348194, 0.00023592798970639706, -8.444768900517374e-05, -0.001976519590243697, -0.00010703324369387701, 1.0]]
finish sampling actions
the shape of torch.tensor(info['observations']['image_primary']) is: (256, 256, 3)
Episode return: 0.0
the shape: (10, 256, 256, 3)